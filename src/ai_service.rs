use anyhow::Result;
use serde::{Deserialize, Serialize};
use serde_json::json;
use chrono::Utc;
use rbatis::RBatis;
use crate::models::AchievementRequirementType;
use crate::ai_tasks::AnalysisDirection;
use crate::config::AIConfig;
use crate::behavior_analytics::{UserBehaviorSummary, BehaviorAnalytics};

// æ ¼å¼åŒ– AI è¼¸å‡ºç‚ºå–®è¡Œæ—¥èªŒ
fn format_ai_output(text: &str) -> String {
    text.replace("\\n", " ")
        .replace("\\\"", "\"")
        .chars()
        .filter(|c| !c.is_control() || *c == ' ')
        .collect::<String>()
        .split_whitespace()
        .collect::<Vec<_>>()
        .join(" ")
}

// å°ˆå®¶æ•¸æ“šåº«
pub fn get_expert_database() -> Vec<Expert> {
    vec![
        Expert {
            name: "è³‡æ·±è‹±æ–‡æ•™å­¸è€å¸«".to_string(),
            description: "æ“æœ‰15å¹´è‹±èªæ•™å­¸ç¶“é©—ï¼Œå°ˆç²¾æ–¼èªè¨€å­¸ç¿’æ–¹æ³•å’ŒæŠ€å·§".to_string(),
            expertise_areas: vec!["è‹±èªå­¸ç¿’".to_string(), "èªè¨€æ•™å­¸".to_string(), "å£èªç·´ç¿’".to_string(), "æ–‡æ³•å­¸ç¿’".to_string()],
            emoji: "ğŸ“š".to_string(),
        },
        Expert {
            name: "ç¨‹å¼è¨­è¨ˆå°å¸«".to_string(),
            description: "è³‡æ·±è»Ÿé«”å·¥ç¨‹å¸«ï¼Œå°ˆç²¾æ–¼å¤šç¨®ç¨‹å¼èªè¨€å’Œé–‹ç™¼æ¡†æ¶".to_string(),
            expertise_areas: vec!["ç¨‹å¼è¨­è¨ˆ".to_string(), "è»Ÿé«”é–‹ç™¼".to_string(), "æ¼”ç®—æ³•".to_string(), "ç³»çµ±è¨­è¨ˆ".to_string()],
            emoji: "ğŸ’»".to_string(),
        },
        Expert {
            name: "å¥èº«æ•™ç·´".to_string(),
            description: "å°ˆæ¥­å¥èº«æ•™ç·´ï¼Œå°ˆç²¾æ–¼é‹å‹•è¨“ç·´å’Œå¥åº·ç®¡ç†".to_string(),
            expertise_areas: vec!["å¥èº«è¨“ç·´".to_string(), "é‹å‹•è¨ˆåŠƒ".to_string(), "å¥åº·ç®¡ç†".to_string(), "ç‡Ÿé¤Šæ­é…".to_string()],
            emoji: "ğŸ’ª".to_string(),
        },
        Expert {
            name: "ç†è²¡è¦åŠƒå¸«".to_string(),
            description: "å°ˆæ¥­ç†è²¡é¡§å•ï¼Œå°ˆç²¾æ–¼æŠ•è³‡ç†è²¡å’Œè²¡å‹™è¦åŠƒ".to_string(),
            expertise_areas: vec!["ç†è²¡è¦åŠƒ".to_string(), "æŠ•è³‡ç­–ç•¥".to_string(), "è²¡å‹™ç®¡ç†".to_string(), "å„²è“„è¨ˆåŠƒ".to_string()],
            emoji: "ğŸ’°".to_string(),
        },
        Expert {
            name: "æ™‚é–“ç®¡ç†é¡§å•".to_string(),
            description: "å°ˆæ¥­æ™‚é–“ç®¡ç†é¡§å•ï¼Œå°ˆç²¾æ–¼æ•ˆç‡æå‡å’Œç›®æ¨™é”æˆ".to_string(),
            expertise_areas: vec!["æ™‚é–“ç®¡ç†".to_string(), "æ•ˆç‡æå‡".to_string(), "ç›®æ¨™è¨­å®š".to_string(), "ç¿’æ…£é¤Šæˆ".to_string()],
            emoji: "â°".to_string(),
        },
        Expert {
            name: "å‰µæ„è¨­è¨ˆå¸«".to_string(),
            description: "è³‡æ·±è¨­è¨ˆå¸«ï¼Œå°ˆç²¾æ–¼å‰µæ„æ€ç¶­å’Œè¦–è¦ºè¨­è¨ˆ".to_string(),
            expertise_areas: vec!["å‰µæ„è¨­è¨ˆ".to_string(), "è¦–è¦ºè¨­è¨ˆ".to_string(), "å“ç‰Œè¨­è¨ˆ".to_string(), "UI/UXè¨­è¨ˆ".to_string()],
            emoji: "ğŸ¨".to_string(),
        },
        Expert {
            name: "å¿ƒç†è«®å•†å¸«".to_string(),
            description: "å°ˆæ¥­å¿ƒç†è«®å•†å¸«ï¼Œå°ˆç²¾æ–¼æƒ…ç·’ç®¡ç†å’Œå¿ƒç†èª¿é©".to_string(),
            expertise_areas: vec!["å¿ƒç†è«®å•†".to_string(), "æƒ…ç·’ç®¡ç†".to_string(), "å£“åŠ›èª¿é©".to_string(), "äººéš›é—œä¿‚".to_string()],
            emoji: "ğŸ§ ".to_string(),
        },
        Expert {
            name: "å»šè—å°å¸«".to_string(),
            description: "å°ˆæ¥­å»šå¸«ï¼Œå°ˆç²¾æ–¼å„ç¨®æ–™ç†æŠ€å·§å’Œç‡Ÿé¤Šæ­é…".to_string(),
            expertise_areas: vec!["çƒ¹é£ªæŠ€å·§".to_string(), "æ–™ç†è£½ä½œ".to_string(), "ç‡Ÿé¤Šæ­é…".to_string(), "é£Ÿæé¸æ“‡".to_string()],
            emoji: "ğŸ‘¨â€ğŸ³".to_string(),
        },
        Expert {
            name: "éŸ³æ¨‚è€å¸«".to_string(),
            description: "å°ˆæ¥­éŸ³æ¨‚æ•™å¸«ï¼Œå°ˆç²¾æ–¼æ¨‚å™¨æ¼”å¥å’ŒéŸ³æ¨‚ç†è«–".to_string(),
            expertise_areas: vec!["éŸ³æ¨‚å­¸ç¿’".to_string(), "æ¨‚å™¨æ¼”å¥".to_string(), "éŸ³æ¨‚ç†è«–".to_string(), "è²æ¨‚è¨“ç·´".to_string()],
            emoji: "ğŸµ".to_string(),
        },
        Expert {
            name: "å­¸ç¿’æ–¹æ³•é¡§å•".to_string(),
            description: "æ•™è‚²å¿ƒç†å­¸å°ˆå®¶ï¼Œå°ˆç²¾æ–¼å­¸ç¿’æ–¹æ³•å’Œè¨˜æ†¶æŠ€å·§".to_string(),
            expertise_areas: vec!["å­¸ç¿’æ–¹æ³•".to_string(), "è¨˜æ†¶æŠ€å·§".to_string(), "è€ƒè©¦æº–å‚™".to_string(), "çŸ¥è­˜ç®¡ç†".to_string()],
            emoji: "ğŸ“–".to_string(),
        },
    ]
}

// OpenAI API è«‹æ±‚çµæ§‹
#[derive(Serialize)]
struct OpenAIRequest {
    model: String,
    messages: Vec<ChatMessage>,
    // temperature æ–°æ¨¡å‹åªæ”¯æŒé»˜èªå€¼ 1ï¼Œå› æ­¤ä¸å†å‚³é
    max_completion_tokens: i32,
    response_format: ResponseFormat,
}

#[derive(Serialize)]
struct ResponseFormat {
    #[serde(rename = "type")]
    format_type: String,
}

#[derive(Serialize, Deserialize)]
struct ChatMessage {
    role: String,
    content: String,
}

// OpenAI API å›æ‡‰çµæ§‹
#[derive(Deserialize)]
struct OpenAIResponse {
    choices: Vec<Choice>,
}

#[derive(Deserialize)]
struct Choice {
    message: ChatMessage,
}

// å°ˆå®¶ä¿¡æ¯çµæ§‹
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct Expert {
    pub name: String,
    pub description: String,
    pub expertise_areas: Vec<String>,
    pub emoji: String,
}

// å°ˆå®¶åŒ¹é…çµæœ
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ExpertMatch {
    pub expert: Expert,
    pub confidence: f64,
    pub ai_expert_name: String,
    pub ai_expert_description: String,
}

// AI ç”Ÿæˆçš„ä»»å‹™çµæ§‹ï¼ˆç°¡åŒ–ç‰ˆï¼‰
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AIGeneratedTask {
    pub title: String,
    pub description: Option<String>,
    pub task_type: String,
    pub priority: i32,
    pub difficulty: i32,
    pub experience: i32,
    pub due_date: Option<String>,
    pub is_recurring: bool,
    pub recurrence_pattern: Option<String>,
    pub start_date: Option<String>,
    pub end_date: Option<String>,
    pub completion_target: Option<f64>,
}

// AI ç”Ÿæˆçš„ä»»å‹™è¨ˆåŠƒï¼ˆåŒ…å«ä¸»ä»»å‹™å’Œå­ä»»å‹™ï¼‰
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AIGeneratedTaskPlan {
    pub main_task: AIGeneratedTask,
    pub subtasks: Vec<AIGeneratedTask>,
}

// AI ç”Ÿæˆçš„æˆå°±çµæ§‹
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct AIGeneratedAchievement {
    pub name: String,
    pub description: Option<String>,
    pub icon: Option<String>,
    pub category: String,
    pub requirement_type: String,
    pub requirement_value: i32,
    pub experience_reward: i32,
}

// ===== è¾…åŠ©å‡½æ•°ï¼šæ„å»ºåŸºäºç»Ÿè®¡æ‘˜è¦çš„ Prompt =====

/// æ ¹æ®ç”¨æˆ·è¡Œä¸ºæ‘˜è¦æ„å»ºæˆå°±ç”Ÿæˆçš„ prompt
fn build_achievement_prompt_from_summary(summary: &UserBehaviorSummary) -> String {
    // æ ¼å¼åŒ–åˆ†ç±»ç»Ÿè®¡
    let top_categories: Vec<String> = summary.top_categories
        .iter()
        .map(|c| format!(
            "{}ï¼ˆå®Œæˆ{}æ¬¡ï¼Œå®Œæˆç‡{:.0}%ï¼Œå¹³å‡éš¾åº¦{:.1}ï¼‰",
            c.category,
            c.completed_count,
            c.completion_rate * 100.0,
            c.avg_difficulty
        ))
        .collect();

    // æ ¼å¼åŒ–æœ€è¿‘å®Œæˆçš„ä»»åŠ¡
    let recent_tasks: Vec<String> = summary.recent_completions
        .iter()
        .take(10)
        .map(|t| format!("  - {}: {}", t.completion_date.split('T').next().unwrap_or(&t.completion_date), t.title))
        .collect();

    // æ ¼å¼åŒ–æœ€è¿‘å–æ¶ˆçš„ä»»åŠ¡
    let recent_cancellations: Vec<String> = summary.recent_cancellations
        .iter()
        .take(5)
        .map(|t| format!("  - {}: {}", t.completion_date.split('T').next().unwrap_or(&t.completion_date), t.title))
        .collect();

    // æ ¼å¼åŒ–é‡Œç¨‹ç¢‘
    let milestones: Vec<String> = summary.milestone_events
        .iter()
        .map(|m| format!("  - {}: {}", m.event_type, m.description))
        .collect();

    format!(
        r#"ä½ æ˜¯ä¸€å€‹æˆå°±è¨­è¨ˆåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„è¡Œç‚ºæ•¸æ“šåˆ†æï¼Œç”Ÿæˆå€‹æ€§åŒ–ä¸”å…·æœ‰æ¿€å‹µæ€§çš„æˆå°±ã€‚

ã€ç”¨æˆ¶çµ±è¨ˆæ•¸æ“šã€‘
- ç¸½å®Œæˆä»»å‹™ï¼š{total_completed} æ¬¡
- ç¸½å–æ¶ˆä»»å‹™ï¼š{total_cancelled} æ¬¡
- å¾…è™•ç†ä»»å‹™ï¼š{total_pending} å€‹
- æœ€é•·é€£çºŒè¨˜éŒ„ï¼š{longest_streak} å¤©ï¼ˆ{streak_task}ï¼‰
- ç•¶å‰é€£çºŒï¼š{current_streak} å¤©
- è¿‘ 30 å¤©æ´»èºï¼š{active_30} å¤©
- ç¸½ç¶“é©—å€¼ï¼š{total_exp}

ã€ä»»å‹™åˆ†é¡åˆ†å¸ƒã€‘ï¼ˆTop {cat_count}ï¼‰
{categories}

ã€æœ€è¿‘å®Œæˆä»»å‹™ã€‘ï¼ˆæœ€è¿‘ {recent_count} æ¢æ¨£æœ¬ï¼‰
{recent_tasks}

ã€æœ€è¿‘å–æ¶ˆä»»å‹™ã€‘ï¼ˆæœ€è¿‘ {cancel_count} æ¢æ¨£æœ¬ï¼‰
{recent_cancellations}

ã€é‡Œç¨‹ç¢‘äº‹ä»¶ã€‘
{milestones}

ã€å·²è§£é–æˆå°±ã€‘
{achievements}

**è¨­è¨ˆåŸå‰‡ï¼š**
- æˆå°±åç¨±è¦å¹½é»˜ä¸”å…·é«”ï¼Œå¦‚ã€Œæˆç‚ºè‹±èªå­—å…¸ã€ã€Œè·‘ç«å…¥é­”ã€
- åŸºæ–¼ç”¨æˆ¶å¯¦éš›è¡Œç‚ºæ¨¡å¼ç”Ÿæˆï¼Œä¸è¦æ†‘ç©ºæƒ³åƒ
- è€ƒæ…®ç”¨æˆ¶çš„å„ªå‹¢é ˜åŸŸï¼ˆå®Œæˆç‡é«˜çš„åˆ†é¡ï¼‰å’Œæ½›åŠ›é ˜åŸŸ
- é¿å…èˆ‡ç¾æœ‰æˆå°±é‡è¤‡
- å¦‚æœæœ‰æ˜é¡¯çš„é€£çºŒè¨˜éŒ„ï¼Œå¯ä»¥è€ƒæ…®ç›¸é—œçš„æŒçºŒæ€§æˆå°±

**æˆå°±åˆ†é¡ï¼š**
- task_mastery: ä»»å‹™ç²¾é€šé¡
- consistency: æŒçºŒæ€§é¡
- challenge_overcome: å…‹æœæŒ‘æˆ°é¡
- skill_development: æŠ€èƒ½ç™¼å±•é¡

**é”æˆæ¢ä»¶é¡å‹ï¼š**
- consecutive_days: é€£çºŒå¤©æ•¸
- total_completions: ç¸½å®Œæˆæ¬¡æ•¸
- task_complete: å®Œæˆä»»å‹™ç¸½æ•¸
- streak_recovery: å¾å¤±æ•—ä¸­æ¢å¾©
- skill_level: æŠ€èƒ½ç­‰ç´š
- learning_task_complete: å­¸ç¿’ä»»å‹™å®Œæˆ
- intelligence_attribute: æ™ºåŠ›å±¬æ€§é”æˆ
- endurance_attribute: æ¯…åŠ›å±¬æ€§é”æˆ
- creativity_attribute: å‰µé€ åŠ›å±¬æ€§é”æˆ
- social_attribute: ç¤¾äº¤åŠ›å±¬æ€§é”æˆ
- focus_attribute: å°ˆæ³¨åŠ›å±¬æ€§é”æˆ
- adaptability_attribute: é©æ‡‰åŠ›å±¬æ€§é”æˆ

**ç¶“é©—å€¼çå‹µè¨ˆç®—ï¼š**
- åŸºæ–¼é›£åº¦ï¼šç°¡å–®æˆå°± 50-100ï¼Œä¸­ç­‰ 100-200ï¼Œå›°é›£ 200-500

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "name": "æˆå°±åç¨±ï¼ˆå¹½é»˜ä¸”å…·é«”ï¼‰",
  "description": "æˆå°±æè¿°ï¼ˆé¸å¡«ï¼‰",
  "icon": "åœ–æ¨™åç¨±ï¼ˆé¸å¡«ï¼‰",
  "category": "æˆå°±åˆ†é¡",
  "requirement_type": "é”æˆæ¢ä»¶é¡å‹",
  "requirement_value": æ•¸å€¼,
  "experience_reward": ç¶“é©—å€¼çå‹µ
}}"#,
        total_completed = summary.total_tasks_completed,
        total_cancelled = summary.total_tasks_cancelled,
        total_pending = summary.total_tasks_pending,
        longest_streak = summary.longest_streak.days,
        streak_task = summary.longest_streak.task_title,
        current_streak = summary.current_streak.days,
        active_30 = summary.active_days_last_30,
        total_exp = summary.total_experience,
        cat_count = summary.top_categories.len(),
        categories = if top_categories.is_empty() { "  ï¼ˆæš«ç„¡æ•¸æ“šï¼‰".to_string() } else { top_categories.join("\n") },
        recent_count = summary.recent_completions.len().min(10),
        recent_tasks = if recent_tasks.is_empty() { "  ï¼ˆæš«ç„¡æ•¸æ“šï¼‰".to_string() } else { recent_tasks.join("\n") },
        cancel_count = summary.recent_cancellations.len().min(5),
        recent_cancellations = if recent_cancellations.is_empty() { "  ï¼ˆæš«ç„¡æ•¸æ“šï¼‰".to_string() } else { recent_cancellations.join("\n") },
        milestones = if milestones.is_empty() { "  ï¼ˆæš«ç„¡æ•¸æ“šï¼‰".to_string() } else { milestones.join("\n") },
        achievements = if summary.unlocked_achievements.is_empty() { "ï¼ˆæš«ç„¡ï¼‰".to_string() } else { summary.unlocked_achievements.join("ã€") },
    )
}

// AI æœå‹™ trait
#[async_trait::async_trait]
pub trait AIService {
    async fn generate_achievement_from_text(&self, user_input: &str) -> Result<AIGeneratedAchievement>;
    async fn generate_achievement_from_user_id(&self, rb: &RBatis, user_id: &str) -> Result<AIGeneratedAchievement>;
    async fn generate_task_preview(&self, prompt: &str) -> Result<String>;
    async fn generate_task_preview_with_history(&self, system_prompt: &str, history: &[(String, String)], current_message: &str) -> Result<String>;
    async fn generate_task_from_text(&self, user_input: &str) -> Result<AIGeneratedTask>;
    async fn match_expert_for_task(&self, user_input: &str) -> Result<ExpertMatch>;
    async fn generate_task_with_expert(&self, user_input: &str, expert_match: &ExpertMatch) -> Result<AIGeneratedTaskPlan>;
    async fn analyze_with_expert(&self, user_input: &str, expert_name: &str, expert_description: &str, analysis_type: &str) -> Result<String>;

    // æ–°å¢ï¼šä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”Ÿæˆæ–‡å­—å›æ‡‰
    async fn generate_with_model(&self, model: &str, prompt: &str) -> Result<String>;
}

// OpenRouter API è«‹æ±‚çµæ§‹
#[derive(Serialize)]
struct OpenRouterRequest {
    model: String,
    messages: Vec<ChatMessage>,
    max_completion_tokens: i32,
    response_format: ResponseFormat,
}

// OpenRouter API å›æ‡‰çµæ§‹
#[derive(Deserialize)]
struct OpenRouterResponse {
    choices: Vec<Choice>,
}

pub struct OpenAIService {
    api_key: String,
    model: String,
    client: reqwest::Client,
}

impl OpenAIService {
    pub fn new(api_key: String, model: String) -> Self {
        Self {
            api_key,
            model,
            client: reqwest::Client::new(),
        }
    }
}

#[async_trait::async_trait]
impl AIService for OpenAIService {

    async fn generate_achievement_from_text(&self, user_input: &str) -> Result<AIGeneratedAchievement> {
        let system_prompt = r#"ä½ æ˜¯ä¸€å€‹æˆå°±è¨­è¨ˆåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„è¡Œç‚ºæ•¸æ“šåˆ†æï¼Œç”Ÿæˆå€‹æ€§åŒ–ä¸”å…·æœ‰æ¿€å‹µæ€§çš„æˆå°±ã€‚

è«‹ä»”ç´°åˆ†æç”¨æˆ¶çš„ï¼š
1. å·²æœ‰æˆå°±åˆ—è¡¨
2. ä»»å‹™å®Œæˆç‹€æ³
3. ä»»å‹™å–æ¶ˆ/å¤±æ•—ç‹€æ³
4. å¾…å®Œæˆä»»å‹™

**è¨­è¨ˆåŸå‰‡ï¼š**
- æˆå°±åç¨±è¦å¹½é»˜ä¸”å…·é«”ï¼Œå¦‚ã€Œæˆç‚ºè‹±èªå­—å…¸ã€ã€Œè·‘ç«å…¥é­”ã€
- åŸºæ–¼ç”¨æˆ¶å¯¦éš›è¡Œç‚ºæ¨¡å¼ç”Ÿæˆï¼Œä¸è¦æ†‘ç©ºæƒ³åƒ
- å¦‚æœç”¨æˆ¶åœ¨æŸé ˜åŸŸå·²æœ‰åŸºç¤æˆå°±ä¸”è¡¨ç¾å„ªç§€ï¼Œå¯è€ƒæ…®å‡ç´šç‰ˆæˆå°±
- é¿å…èˆ‡ç¾æœ‰æˆå°±é‡è¤‡

**æˆå°±åˆ†é¡ï¼š**
- task_mastery: ä»»å‹™ç²¾é€šé¡
- consistency: æŒçºŒæ€§é¡  
- challenge_overcome: å…‹æœæŒ‘æˆ°é¡
- skill_development: æŠ€èƒ½ç™¼å±•é¡

**é”æˆæ¢ä»¶é¡å‹ï¼š**
- consecutive_days: é€£çºŒå¤©æ•¸
- total_completions: ç¸½å®Œæˆæ¬¡æ•¸  
- task_complete: å®Œæˆä»»å‹™ç¸½æ•¸
- streak_recovery: å¾å¤±æ•—ä¸­æ¢å¾©
- skill_level: æŠ€èƒ½ç­‰ç´š
- learning_task_complete: å­¸ç¿’ä»»å‹™å®Œæˆ
- intelligence_attribute: æ™ºåŠ›å±¬æ€§é”æˆ
- endurance_attribute: æ¯…åŠ›å±¬æ€§é”æˆ  
- creativity_attribute: å‰µé€ åŠ›å±¬æ€§é”æˆ
- social_attribute: ç¤¾äº¤åŠ›å±¬æ€§é”æˆ
- focus_attribute: å°ˆæ³¨åŠ›å±¬æ€§é”æˆ
- adaptability_attribute: é©æ‡‰åŠ›å±¬æ€§é”æˆ

**ç¶“é©—å€¼çå‹µè¨ˆç®—ï¼š**
- åŸºæ–¼é›£åº¦ï¼šç°¡å–®æˆå°± 50-100ï¼Œä¸­ç­‰ 100-200ï¼Œå›°é›£ 200-500

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{
  "name": "æˆå°±åç¨±ï¼ˆå¹½é»˜ä¸”å…·é«”ï¼‰",
  "description": "æˆå°±æè¿°ï¼ˆé¸å¡«ï¼‰", 
  "icon": "åœ–æ¨™åç¨±ï¼ˆé¸å¡«ï¼‰",
  "category": "æˆå°±åˆ†é¡",
  "requirement_type": "é”æˆæ¢ä»¶é¡å‹",
  "requirement_value": æ•¸å€¼,
  "experience_reward": ç¶“é©—å€¼çå‹µ
}

ç¯„ä¾‹ï¼š
è¼¸å…¥ï¼šä½¿ç”¨è€…é€£çºŒå®Œæˆã€ŒèƒŒè‹±èªå–®å­—ã€30å¤©ï¼Œä½†ç¶“å¸¸å–æ¶ˆã€Œé‹å‹•ã€ä»»å‹™
è¼¸å‡ºï¼š
{
  "name": "æˆç‚ºè‹±èªå­—å…¸",
  "description": "é€£çºŒ30å¤©å®ŒæˆèƒŒè‹±èªå–®å­—ï¼Œè©å½™é‡å·²ç¶“è¶…è¶Šä¸€èˆ¬å­—å…¸",
  "icon": "ğŸ“–",
  "category": "task_mastery",
  "requirement_type": "consecutive_days", 
  "requirement_value": 30,
  "experience_reward": 300
}"#;

        let user_message = format!("è«‹æ ¹æ“šä»¥ä¸‹ç”¨æˆ¶è¡Œç‚ºæ•¸æ“šç”Ÿæˆåˆé©çš„æˆå°±ï¼š{}", user_input);

        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt.to_string(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_message.clone(),
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_achievement_from_text] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_achievement_from_text] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openai_response.choices.first() {
            let achievement_json = &choice.message.content;
            let generated_achievement: AIGeneratedAchievement = serde_json::from_str(achievement_json)?;

            validate_generated_achievement(&generated_achievement)?;

            Ok(generated_achievement)
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_preview(&self, prompt: &str) -> Result<String> {
        let request = serde_json::json!({
            "model": self.model.clone(),
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹å……æ»¿æ´»åŠ›å’Œé¼“å‹µçš„ä»»å‹™åŠ©æ‰‹ã€‚ç”¨ç©æ¥µæ­£é¢çš„èªæ°£ç‚ºç”¨æˆ¶ä»‹ç´¹ä»»å‹™ï¼Œè®“ä»–å€‘æ„Ÿåˆ°èˆˆå¥®å’Œæœ‰å‹•åŠ›å»å®Œæˆã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_completion_tokens": 4000
        });

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_preview] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_preview] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;
        
        if let Some(choice) = openai_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_preview_with_history(&self, system_prompt: &str, history: &[(String, String)], current_message: &str) -> Result<String> {
        let mut messages = vec![];

        // å…ˆæ·»åŠ æ­·å²å°è©±
        for (user_msg, assistant_msg) in history {
            messages.push(serde_json::json!({
                "role": "user",
                "content": user_msg
            }));
            messages.push(serde_json::json!({
                "role": "assistant",
                "content": assistant_msg
            }));
        }

        // ç„¶å¾Œæ·»åŠ ç³»çµ±æç¤ºè©
        messages.push(serde_json::json!({
            "role": "system",
            "content": system_prompt
        }));

        // æœ€å¾Œæ·»åŠ ç•¶å‰ç”¨æˆ¶è¨Šæ¯
        messages.push(serde_json::json!({
            "role": "user",
            "content": current_message
        }));

        let request = serde_json::json!({
            "model": self.model.clone(),
            "messages": messages,
            "max_completion_tokens": 4000
        });

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_preview_with_history] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_preview_with_history] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;
        
        if let Some(choice) = openai_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_from_text(&self, user_input: &str) -> Result<AIGeneratedTask> {
        // ç²å–ç•¶å‰æ™‚é–“ä¸¦æ ¼å¼åŒ–
        let now = Utc::now();
        let current_time_str = now.to_rfc3339(); // e.g., "2025-08-17T12:00:00Z"

        let system_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹ä»»å‹™è¦åŠƒåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„è‡ªç„¶èªè¨€æè¿°ï¼Œç”Ÿæˆçµæ§‹åŒ–çš„ä»»å‹™è³‡æ–™ã€‚

**é‡è¦ï¼šç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚** åœ¨ç”Ÿæˆä»»ä½•èˆ‡æ—¥æœŸç›¸é—œçš„æ¬„ä½ï¼ˆå¦‚ start_date, due_dateï¼‰æ™‚ï¼Œè«‹ä»¥æ­¤æ™‚é–“ç‚ºåŸºæº–é€²è¡Œæ¨ç®—ã€‚

**æˆªæ­¢æ—¥æœŸç”Ÿæˆè¦å‰‡ï¼š**
- å°æ–¼å¤§éƒ¨åˆ†ä»»å‹™ï¼Œä½ éƒ½æ‡‰è©²è¨­å®šä¸€å€‹åˆç†çš„æˆªæ­¢æ—¥æœŸ
- çŸ­æœŸä»»å‹™ï¼ˆ1-3å¤©å…§å®Œæˆï¼‰ï¼šè¨­å®š1-3å¤©å¾Œçš„æˆªæ­¢æ—¥æœŸ
- ä¸­æœŸä»»å‹™ï¼ˆ1-2é€±å®Œæˆï¼‰ï¼šè¨­å®š1-2é€±å¾Œçš„æˆªæ­¢æ—¥æœŸ
- é•·æœŸä»»å‹™ï¼ˆ1å€‹æœˆä»¥ä¸Šï¼‰ï¼šè¨­å®š1-3å€‹æœˆå¾Œçš„æˆªæ­¢æ—¥æœŸ
- åªæœ‰å°æ–¼æ²’æœ‰æ˜ç¢ºæ™‚é–“é™åˆ¶çš„ç¿’æ…£é¡ä»»å‹™æ‰è¨­å®š due_date ç‚º null
- å¦‚æœç”¨æˆ¶æ˜ç¢ºæåˆ°æ™‚é–“ï¼ˆå¦‚"æ˜å¤©"ã€"ä¸‹é€±"ã€"æœˆåº•"ï¼‰ï¼Œä¸€å®šè¦æ ¹æ“šç•¶å‰æ™‚é–“è¨ˆç®—å°æ‡‰çš„æˆªæ­¢æ—¥æœŸ

ä»»å‹™é¡å‹èªªæ˜ï¼š
- main: ä¸»è¦ä»»å‹™ï¼ˆé‡è¦çš„é•·æœŸç›®æ¨™ï¼Œé€šå¸¸è¨­å®šè¼ƒé•·çš„æˆªæ­¢æ—¥æœŸï¼‰
- side: å‰¯ç·šä»»å‹™ï¼ˆæ¬¡è¦çš„çŸ­æœŸä»»å‹™ï¼Œé€šå¸¸è¨­å®šè¼ƒçŸ­çš„æˆªæ­¢æ—¥æœŸï¼‰
- challenge: æŒ‘æˆ°ä»»å‹™ï¼ˆå›°é›£ä¸”æœ‰æˆå°±æ„Ÿçš„ä»»å‹™ï¼Œæ ¹æ“šå…·é«”å…§å®¹è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰
- daily: æ—¥å¸¸ä»»å‹™ï¼ˆä¾‹è¡Œæ€§ä»»å‹™ï¼Œé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰

å„ªå…ˆç´šï¼š0=ä½, 1=ä¸­, 2=é«˜
é›£åº¦ï¼š1-5ï¼ˆ1=éå¸¸ç°¡å–®, 5=éå¸¸å›°é›£ï¼‰
ç¶“é©—å€¼ï¼šæ ¹æ“šé›£åº¦å’Œé‡è¦æ€§è¨ˆç®—ï¼Œé€šå¸¸æ˜¯ difficulty * 20 + priority * 10

é‡è¤‡æ¨¡å¼ï¼ˆåƒ…é™æ—¥å¸¸ä»»å‹™ï¼‰ï¼š
- daily: æ¯å¤©
- weekdays: å·¥ä½œæ—¥
- weekends: é€±æœ«
- weekly: æ¯é€±

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
  "title": "ä»»å‹™æ¨™é¡Œ",
  "description": "ä»»å‹™æè¿°ï¼ˆé¸å¡«ï¼‰",
  "task_type": "main/side/challenge/daily",
  "priority": 0-2,
  "difficulty": 1-5,
  "experience": ç¶“é©—å€¼,
  "due_date": "æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼Œå¤§å¤šæ•¸æƒ…æ³ä¸‹éƒ½æ‡‰è©²è¨­å®šï¼‰",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}

å¦‚æœæ˜¯é‡è¤‡æ€§ä»»å‹™ï¼Œè«‹è¨­ç½®ï¼š
- is_recurring: true
- recurrence_pattern: "daily/weekdays/weekends/weekly"
- start_date: é–‹å§‹æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰
- completion_target: 0.8ï¼ˆé è¨­80%å®Œæˆç‡ç›®æ¨™ï¼‰
- due_date: nullï¼ˆé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šå–®ä¸€æˆªæ­¢æ—¥æœŸï¼‰

ç¯„ä¾‹è¼¸å…¥ï¼š"å­¸ç¿’Pythonç¨‹å¼è¨­è¨ˆ"
ç¯„ä¾‹è¼¸å‡ºï¼š
{{
  "title": "å­¸ç¿’Pythonç¨‹å¼è¨­è¨ˆ",
  "description": "ç³»çµ±æ€§å­¸ç¿’Pythonç¨‹å¼èªè¨€åŸºç¤çŸ¥è­˜",
  "task_type": "main",
  "priority": 2,
  "difficulty": 3,
  "experience": 80,
  "due_date": "2024-02-15T23:59:59Z",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}

ç¯„ä¾‹è¼¸å…¥ï¼š"æ˜å¤©äº¤å ±å‘Š"
ç¯„ä¾‹è¼¸å‡ºï¼š
{{
  "title": "å®Œæˆä¸¦æäº¤å ±å‘Š",
  "description": "æ•´ç†è³‡æ–™ä¸¦å®Œæˆå ±å‘Šæ’°å¯«",
  "task_type": "side",
  "priority": 2,
  "difficulty": 2,
  "experience": 60,
  "due_date": "2024-01-02T18:00:00Z",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}"#,
            current_time_str
        );

        let user_message = format!("è«‹æ ¹æ“šä»¥ä¸‹æè¿°ç”Ÿæˆä»»å‹™ï¼š{}", user_input);

        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_message,
                },
            ],
            max_completion_tokens: 500,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_from_text] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_from_text] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;
        
        if let Some(choice) = openai_response.choices.first() {
            let task_json = &choice.message.content;
            log::info!("[AI OUTPUT][generate_task_from_text] {}", format_ai_output(&task_json));
            let generated_task: AIGeneratedTask = serde_json::from_str(task_json)?;
            
            // é©—è­‰ç”Ÿæˆçš„ä»»å‹™
            validate_generated_task(&generated_task)?;
            
            Ok(generated_task)
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    // æ–°æ–¹æ³•ï¼šåŸºäºç”¨æˆ· ID ç”Ÿæˆæˆå°±ï¼ˆä½¿ç”¨ç»Ÿè®¡æ‘˜è¦ï¼‰
    async fn generate_achievement_from_user_id(&self, rb: &RBatis, user_id: &str) -> Result<AIGeneratedAchievement> {
        // 1. ç”Ÿæˆç”¨æˆ·è¡Œä¸ºæ‘˜è¦
        log::info!("ä¸ºç”¨æˆ· {} ç”Ÿæˆè¡Œä¸ºæ‘˜è¦...", user_id);
        let summary = BehaviorAnalytics::generate_summary(rb, user_id).await?;
        log::info!("è¡Œä¸ºæ‘˜è¦ç”Ÿæˆå®Œæˆï¼šå®Œæˆ{}ä¸ªä»»åŠ¡ï¼Œæœ€é•¿è¿ç»­{}å¤©", summary.total_tasks_completed, summary.longest_streak.days);

        // 2. æ„å»ºåŸºäºæ‘˜è¦çš„ prompt
        let system_prompt = build_achievement_prompt_from_summary(&summary);

        // 3. è°ƒç”¨ AI ç”Ÿæˆæˆå°±
        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: "è«‹åŸºæ–¼ä»¥ä¸Šç”¨æˆ¶æ•¸æ“šï¼Œç”Ÿæˆä¸€å€‹æœ€åˆé©çš„æˆå°±ã€‚".to_string(),
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_achievement_from_user_id] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_achievement_from_user_id] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openai_response.choices.first() {
            let achievement_json = &choice.message.content;
            let generated_achievement: AIGeneratedAchievement = serde_json::from_str(achievement_json)?;

            // é©—è­‰ç”Ÿæˆçš„æˆå°±
            validate_generated_achievement(&generated_achievement)?;

            Ok(generated_achievement)
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn match_expert_for_task(&self, user_input: &str) -> Result<ExpertMatch> {
        let experts = get_expert_database();
        
        // æ§‹å»ºå°ˆå®¶åŒ¹é…çš„æç¤ºè©
        let expert_list = experts.iter()
            .enumerate()
            .map(|(i, expert)| {
                format!("{}. {} ({}) - å°ˆç²¾é ˜åŸŸ: {}", 
                    i + 1, 
                    expert.name, 
                    expert.emoji,
                    expert.expertise_areas.join("ã€")
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

        let system_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹å°ˆå®¶åŒ¹é…åŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„ä»»å‹™æè¿°ï¼Œå¾ä»¥ä¸‹å°ˆå®¶åˆ—è¡¨ä¸­é¸æ“‡æœ€é©åˆçš„å°ˆå®¶ã€‚

å¯ç”¨å°ˆå®¶åˆ—è¡¨ï¼š
{}

è«‹åˆ†æç”¨æˆ¶çš„ä»»å‹™æè¿°ï¼Œé¸æ“‡æœ€é©åˆçš„å°ˆå®¶ï¼Œä¸¦æä¾›åŒ¹é…ç†ç”±ã€‚

å›æ‡‰æ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "expert_name": "å°ˆå®¶çš„å®Œæ•´åç¨±",
  "expert_description": "å°ˆå®¶çš„è©³ç´°æè¿°",
  "confidence": åŒ¹é…ä¿¡å¿ƒåº¦ï¼ˆ0.0-1.0ï¼‰
}}

é¸æ“‡åŸå‰‡ï¼š
1. æ ¹æ“šä»»å‹™çš„æ ¸å¿ƒé ˜åŸŸé¸æ“‡å°ˆå®¶
2. è€ƒæ…®å°ˆå®¶çš„å°ˆæ¥­é ˜åŸŸæ˜¯å¦èˆ‡ä»»å‹™åŒ¹é…
3. å¦‚æœæ²’æœ‰å®Œå…¨åŒ¹é…çš„å°ˆå®¶ï¼Œé¸æ“‡æœ€æ¥è¿‘çš„
4. ä¿¡å¿ƒåº¦åŸºæ–¼åŒ¹é…ç¨‹åº¦ï¼šå®Œå…¨åŒ¹é…=1.0ï¼Œéƒ¨åˆ†åŒ¹é…=0.6-0.8ï¼Œå‹‰å¼·åŒ¹é…=0.3-0.5"#,
            expert_list
        );

        log::info!("[AI INPUT][match_expert_for_task] {}", user_input);

        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: (&user_input).to_string(),
                },
            ],
            max_completion_tokens: 500,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][match_expert_for_task_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][match_expert_for_task] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openai_response.choices.first() {
            let match_json = &choice.message.content;
            let match_result: serde_json::Value = serde_json::from_str(match_json)?;
            
            let expert_name = match_result["expert_name"].as_str()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„å°ˆå®¶åç¨±"))?.to_string();
            
            let expert_description = match_result["expert_description"].as_str()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„å°ˆå®¶æè¿°"))?.to_string();
            
            let confidence = match_result["confidence"].as_f64()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„ä¿¡å¿ƒåº¦"))?;

            // ç›´æ¥ä½¿ç”¨AIè¿”å›çš„å°ˆå®¶ä¿¡æ¯ï¼Œå‰µå»ºè™›æ“¬å°ˆå®¶å°è±¡
            let virtual_expert = Expert {
                name: expert_name.clone(),
                description: expert_description.clone(),
                expertise_areas: vec!["AIåŒ¹é…".to_string()],
                emoji: "ğŸ¤–".to_string(),
            };

            Ok(ExpertMatch {
                expert: virtual_expert,
                confidence,
                ai_expert_name: expert_name,
                ai_expert_description: expert_description,
            })
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_with_expert(&self, user_input: &str, expert_match: &ExpertMatch) -> Result<AIGeneratedTaskPlan> {
        let now = Utc::now();
        let current_time_str = now.to_rfc3339();

        let system_prompt = format!(
            r#"ä½ æ˜¯{}ï¼Œ{}

**é‡è¦ï¼šç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚** åœ¨ç”Ÿæˆä»»ä½•èˆ‡æ—¥æœŸç›¸é—œçš„æ¬„ä½ï¼ˆå¦‚ start_date, due_dateï¼‰æ™‚ï¼Œè«‹ä»¥æ­¤æ™‚é–“ç‚ºåŸºæº–é€²è¡Œæ¨ç®—ã€‚

**æˆªæ­¢æ—¥æœŸç”Ÿæˆè¦å‰‡ï¼š**
- å°æ–¼å¤§éƒ¨åˆ†ä»»å‹™ï¼Œä½ éƒ½æ‡‰è©²è¨­å®šä¸€å€‹åˆç†çš„æˆªæ­¢æ—¥æœŸ
- çŸ­æœŸä»»å‹™ï¼ˆ1-3å¤©å…§å®Œæˆï¼‰ï¼šè¨­å®š1-3å¤©å¾Œçš„æˆªæ­¢æ—¥æœŸ
- ä¸­æœŸä»»å‹™ï¼ˆ1-2é€±å®Œæˆï¼‰ï¼šè¨­å®š1-2é€±å¾Œçš„æˆªæ­¢æ—¥æœŸ
- é•·æœŸä»»å‹™ï¼ˆ1å€‹æœˆä»¥ä¸Šï¼‰ï¼šè¨­å®š1-3å€‹æœˆå¾Œçš„æˆªæ­¢æ—¥æœŸ
- åªæœ‰å°æ–¼æ²’æœ‰æ˜ç¢ºæ™‚é–“é™åˆ¶çš„ç¿’æ…£é¡ä»»å‹™æ‰è¨­å®š due_date ç‚º null
- å¦‚æœç”¨æˆ¶æ˜ç¢ºæåˆ°æ™‚é–“ï¼ˆå¦‚"æ˜å¤©"ã€"ä¸‹é€±"ã€"æœˆåº•"ï¼‰ï¼Œä¸€å®šè¦æ ¹æ“šç•¶å‰æ™‚é–“è¨ˆç®—å°æ‡‰çš„æˆªæ­¢æ—¥æœŸ

ä»»å‹™é¡å‹èªªæ˜ï¼š
- main: ä¸»è¦ä»»å‹™ï¼ˆé‡è¦çš„é•·æœŸç›®æ¨™ï¼Œé€šå¸¸è¨­å®šè¼ƒé•·çš„æˆªæ­¢æ—¥æœŸï¼‰
- side: å‰¯ç·šä»»å‹™ï¼ˆæ¬¡è¦çš„çŸ­æœŸä»»å‹™ï¼Œé€šå¸¸è¨­å®šè¼ƒçŸ­çš„æˆªæ­¢æ—¥æœŸï¼‰
- challenge: æŒ‘æˆ°ä»»å‹™ï¼ˆå›°é›£ä¸”æœ‰æˆå°±æ„Ÿçš„ä»»å‹™ï¼Œæ ¹æ“šå…·é«”å…§å®¹è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰
- daily: æ—¥å¸¸ä»»å‹™ï¼ˆä¾‹è¡Œæ€§ä»»å‹™ï¼Œé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰

å„ªå…ˆç´šï¼š0=ä½, 1=ä¸­, 2=é«˜
é›£åº¦ï¼š1-5ï¼ˆ1=éå¸¸ç°¡å–®, 5=éå¸¸å›°é›£ï¼‰
ç¶“é©—å€¼ï¼šæ ¹æ“šé›£åº¦å’Œé‡è¦æ€§è¨ˆç®—ï¼Œé€šå¸¸æ˜¯ difficulty * 20 + priority * 10

**é‡è¦ï¼šä½ å¿…é ˆç”Ÿæˆä¸€å€‹åŒ…å«ä¸»ä»»å‹™å’Œå­ä»»å‹™çš„å®Œæ•´å­¸ç¿’è¨ˆåŠƒã€‚**

è«‹ç‚ºç”¨æˆ¶ç”Ÿæˆä¸€å€‹å®Œæ•´çš„å­¸ç¿’è¨ˆåŠƒï¼ŒåŒ…å«ï¼š
1. ä¸€å€‹ä¸»ä»»å‹™ï¼ˆæ•´é«”å­¸ç¿’ç›®æ¨™ï¼‰
2. 3-5å€‹å…·é«”çš„å­ä»»å‹™

**ä¸»ä»»å‹™è¦æ±‚ï¼š**
- ä½œç‚ºæ•´é«”å­¸ç¿’ç›®æ¨™çš„æ¦‚æ‹¬
- åŒ…å«å­¸ç¿’ç¸½çµå’Œé ä¼°å®Œæˆæ™‚é–“
- è¨­å®šç‚ºé«˜å„ªå…ˆç´šï¼ˆpriority: 2ï¼‰
- é›£åº¦è¨­ç‚ºä¸­ç­‰ï¼ˆdifficulty: 3ï¼‰
- ç¶“é©—å€¼è¨­ç‚º100

**å­ä»»å‹™è¦æ±‚ï¼š**
- ç”Ÿæˆ3-5å€‹å…·é«”çš„å­ä»»å‹™
- æ¯å€‹å­ä»»å‹™éƒ½æ‡‰è©²æœ‰æ˜ç¢ºçš„å­¸ç¿’ç›®æ¨™å’ŒåŸ·è¡Œæ­¥é©Ÿ
- å­ä»»å‹™é›£åº¦å¾ç°¡å–®åˆ°å›°é›£éå¢ï¼ˆ1-4ï¼‰
- æ¯å€‹å­ä»»å‹™éƒ½æ‡‰è©²è¨­å®šåˆç†çš„æˆªæ­¢æ—¥æœŸ
- å­ä»»å‹™é¡å‹å¯ä»¥æ˜¯ï¼šmainï¼ˆä¸»è¦å­¸ç¿’ï¼‰ã€sideï¼ˆè¼”åŠ©ç·´ç¿’ï¼‰ã€challengeï¼ˆæŒ‘æˆ°é …ç›®ï¼‰

**ä½ å¿…é ˆåš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼å›æ‡‰ï¼Œä¸èƒ½æœ‰ä»»ä½•åå·®ï¼š**

{{
  "main_task": {{
    "title": "ä¸»ä»»å‹™æ¨™é¡Œ",
    "description": "ä¸»ä»»å‹™æè¿°ï¼ŒåŒ…å«å­¸ç¿’ç¸½çµå’Œé ä¼°å®Œæˆæ™‚é–“",
    "task_type": "main",
    "priority": 2,
    "difficulty": 3,
    "experience": 100,
    "due_date": "ä¸»ä»»å‹™æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰",
    "is_recurring": false,
    "recurrence_pattern": null,
    "start_date": null,
    "end_date": null,
    "completion_target": null
  }},
  "subtasks": [
    {{
      "title": "å­ä»»å‹™1æ¨™é¡Œ",
      "description": "å­ä»»å‹™1è©³ç´°æè¿°ï¼ŒåŒ…å«å­¸ç¿’ç›®æ¨™å’ŒåŸ·è¡Œæ­¥é©Ÿ",
      "task_type": "main",
      "priority": 1,
      "difficulty": 1,
      "experience": 25,
      "due_date": "å­ä»»å‹™1æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰",
      "is_recurring": false,
      "recurrence_pattern": null,
      "start_date": null,
      "end_date": null,
      "completion_target": null
    }},
    {{
      "title": "å­ä»»å‹™2æ¨™é¡Œ",
      "description": "å­ä»»å‹™2è©³ç´°æè¿°ï¼ŒåŒ…å«å­¸ç¿’ç›®æ¨™å’ŒåŸ·è¡Œæ­¥é©Ÿ",
      "task_type": "side",
      "priority": 1,
      "difficulty": 2,
      "experience": 35,
      "due_date": "å­ä»»å‹™2æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰",
      "is_recurring": false,
      "recurrence_pattern": null,
      "start_date": null,
      "end_date": null,
      "completion_target": null
    }}
  ]
}}

**æ³¨æ„ï¼šä½ çš„å›æ‡‰å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼ŒåŒ…å« main_task å’Œ subtasks å…©å€‹å­—æ®µã€‚ä¸è¦æ·»åŠ ä»»ä½•é¡å¤–çš„æ–‡å­—æˆ–è§£é‡‹ã€‚**"#,
            expert_match.ai_expert_name,
            expert_match.ai_expert_description,
            current_time_str
        );

        log::info!("[AI INPUT][generate_task_with_expert] {}", user_input);

        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: format!("è«‹ç‚ºä»¥ä¸‹ä»»å‹™æè¿°ç”Ÿæˆè©³ç´°çš„ä»»å‹™è¦åŠƒï¼š{}", user_input),
                },
            ],
            max_completion_tokens: 2000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_with_expert_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_with_expert] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;
        
        if let Some(choice) = openai_response.choices.first() {
            let task_json = &choice.message.content;
            let generated_task_plan: AIGeneratedTaskPlan = serde_json::from_str(task_json)?;
            
            // é©—è­‰ç”Ÿæˆçš„ä»»å‹™è¨ˆåŠƒ
            validate_generated_task(&generated_task_plan.main_task)?;
            for subtask in &generated_task_plan.subtasks {
                validate_generated_task(subtask)?;
            }
            
            Ok(generated_task_plan)
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn analyze_with_expert(&self, user_input: &str, expert_name: &str, expert_description: &str, analysis_type: &str) -> Result<String> {
        let analysis_prompts = match analysis_type {
            "analyze" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚åˆ†æå‡º3-6å€‹é©åˆçš„åŠ å¼·æ–¹å‘ã€‚

ç”¨æˆ¶éœ€æ±‚ï¼š{}

è«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "directions": [
    {{"title": "æ–¹å‘æ¨™é¡Œ", "description": "ç°¡çŸ­æè¿°"}},
    {{"title": "æ–¹å‘æ¨™é¡Œ", "description": "ç°¡çŸ­æè¿°"}}
  ]
}}

æ¯å€‹æ–¹å‘æ¨™é¡Œè¦ç°¡æ½”æ˜ç¢ºï¼Œæè¿°è¦ç°¡çŸ­ï¼ˆä¸è¶…é20å­—ï¼‰ã€‚"#,
                expert_name, expert_description, user_input
            ),
            "goals" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚ç”Ÿæˆ3-5å€‹æ˜ç¢ºã€å¯è¡¡é‡çš„å­¸ç¿’ç›®æ¨™ã€‚ç›®æ¨™æ‡‰è©²å…·é«”ã€å¯é”æˆã€æœ‰æ™‚é–“æ€§ã€‚

ç”¨æˆ¶éœ€æ±‚ï¼š{}

è«‹ä»¥æ¸…æ™°çš„æ ¼å¼å›æ‡‰ï¼Œæ¯å€‹ç›®æ¨™ç”¨ç·¨è™Ÿåˆ—å‡ºï¼Œä¸¦èªªæ˜å¦‚ä½•è¡¡é‡é”æˆæƒ…æ³ã€‚"#,
                expert_name, expert_description, user_input
            ),
            "resources" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚æ¨è–¦3-5å€‹å„ªè³ªçš„å­¸ç¿’è³‡æºï¼ŒåŒ…æ‹¬æ›¸ç±ã€èª²ç¨‹ã€ç¶²ç«™ã€å·¥å…·ç­‰ã€‚

ç”¨æˆ¶éœ€æ±‚ï¼š{}

è«‹ä»¥æ¸…æ™°çš„æ ¼å¼å›æ‡‰ï¼Œæ¯å€‹è³‡æºç”¨ç·¨è™Ÿåˆ—å‡ºï¼Œä¸¦ç°¡è¦èªªæ˜ç‚ºä»€éº¼æ¨è–¦é€™å€‹è³‡æºã€‚"#,
                expert_name, expert_description, user_input
            ),
            _ => return Err(anyhow::anyhow!("ä¸æ”¯æ´çš„åˆ†æé¡å‹: {}", analysis_type)),
        };

        log::info!("[AI INPUT][analyze_with_expert] description={} type={} expert_name={} expert_description={}", user_input, analysis_type, expert_name, expert_description);

        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: analysis_prompts,
                },
            ],
            max_completion_tokens: 1000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][analyze_with_expert_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][analyze_with_expert] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openai_response: OpenAIResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openai_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    // æ–°å¢ï¼šä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”Ÿæˆæ–‡å­—å›æ‡‰ï¼ˆOpenAI å¯¦ä½œï¼‰
    async fn generate_with_model(&self, model: &str, prompt: &str) -> Result<String> {
        let request = serde_json::json!({
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_completion_tokens": 4000
        });

        let response = self.client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(anyhow::anyhow!("OpenAI API éŒ¯èª¤: {}", error_text));
        }

        let openai_response: OpenAIResponse = response.json().await?;

        if let Some(choice) = openai_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenAI æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }
}

// OpenRouter æœå‹™å¯¦ç¾
pub struct OpenRouterService {
    api_key: String,
    model: String,
    client: reqwest::Client,
}

impl OpenRouterService {
    pub fn new(api_key: String, model: String) -> Self {
        Self {
            api_key,
            model,
            client: reqwest::Client::new(),
        }
    }
}

#[async_trait::async_trait]
impl AIService for OpenRouterService {
    async fn generate_achievement_from_text(&self, user_input: &str) -> Result<AIGeneratedAchievement> {
        let system_prompt = r#"ä½ æ˜¯ä¸€å€‹æˆå°±è¨­è¨ˆåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„è¡Œç‚ºæ•¸æ“šåˆ†æï¼Œç”Ÿæˆå€‹æ€§åŒ–ä¸”å…·æœ‰æ¿€å‹µæ€§çš„æˆå°±ã€‚

è«‹ä»”ç´°åˆ†æç”¨æˆ¶çš„ï¼š
1. å·²æœ‰æˆå°±åˆ—è¡¨
2. ä»»å‹™å®Œæˆç‹€æ³
3. ä»»å‹™å–æ¶ˆ/å¤±æ•—ç‹€æ³
4. å¾…å®Œæˆä»»å‹™

**è¨­è¨ˆåŸå‰‡ï¼š**
- æˆå°±åç¨±è¦å¹½é»˜ä¸”å…·é«”ï¼Œå¦‚ã€Œæˆç‚ºè‹±èªå­—å…¸ã€ã€Œè·‘ç«å…¥é­”ã€
- åŸºæ–¼ç”¨æˆ¶å¯¦éš›è¡Œç‚ºæ¨¡å¼ç”Ÿæˆï¼Œä¸è¦æ†‘ç©ºæƒ³åƒ
- å¦‚æœç”¨æˆ¶åœ¨æŸé ˜åŸŸå·²æœ‰åŸºç¤æˆå°±ä¸”è¡¨ç¾å„ªç§€ï¼Œå¯è€ƒæ…®å‡ç´šç‰ˆæˆå°±
- é¿å…èˆ‡ç¾æœ‰æˆå°±é‡è¤‡

**æˆå°±åˆ†é¡ï¼š**
- task_mastery: ä»»å‹™ç²¾é€šé¡
- consistency: æŒçºŒæ€§é¡  
- challenge_overcome: å…‹æœæŒ‘æˆ°é¡
- skill_development: æŠ€èƒ½ç™¼å±•é¡

**é”æˆæ¢ä»¶é¡å‹ï¼š**
- consecutive_days: é€£çºŒå¤©æ•¸
- total_completions: ç¸½å®Œæˆæ¬¡æ•¸  
- task_complete: å®Œæˆä»»å‹™ç¸½æ•¸
- streak_recovery: å¾å¤±æ•—ä¸­æ¢å¾©
- skill_level: æŠ€èƒ½ç­‰ç´š
- learning_task_complete: å­¸ç¿’ä»»å‹™å®Œæˆ
- intelligence_attribute: æ™ºåŠ›å±¬æ€§é”æˆ
- endurance_attribute: æ¯…åŠ›å±¬æ€§é”æˆ  
- creativity_attribute: å‰µé€ åŠ›å±¬æ€§é”æˆ
- social_attribute: ç¤¾äº¤åŠ›å±¬æ€§é”æˆ
- focus_attribute: å°ˆæ³¨åŠ›å±¬æ€§é”æˆ
- adaptability_attribute: é©æ‡‰åŠ›å±¬æ€§é”æˆ

**ç¶“é©—å€¼çå‹µè¨ˆç®—ï¼š**
- åŸºæ–¼é›£åº¦ï¼šç°¡å–®æˆå°± 50-100ï¼Œä¸­ç­‰ 100-200ï¼Œå›°é›£ 200-500

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{
  "name": "æˆå°±åç¨±ï¼ˆå¹½é»˜ä¸”å…·é«”ï¼‰",
  "description": "æˆå°±æè¿°ï¼ˆé¸å¡«ï¼‰", 
  "icon": "åœ–æ¨™åç¨±ï¼ˆé¸å¡«ï¼‰",
  "category": "æˆå°±åˆ†é¡",
  "requirement_type": "é”æˆæ¢ä»¶é¡å‹",
  "requirement_value": æ•¸å€¼,
  "experience_reward": ç¶“é©—å€¼çå‹µ
}

ç¯„ä¾‹ï¼š
è¼¸å…¥ï¼šä½¿ç”¨è€…é€£çºŒå®Œæˆã€ŒèƒŒè‹±èªå–®å­—ã€30å¤©ï¼Œä½†ç¶“å¸¸å–æ¶ˆã€Œé‹å‹•ã€ä»»å‹™
è¼¸å‡ºï¼š
{
  "name": "æˆç‚ºè‹±èªå­—å…¸",
  "description": "é€£çºŒ30å¤©å®ŒæˆèƒŒè‹±èªå–®å­—ï¼Œè©å½™é‡å·²ç¶“è¶…è¶Šä¸€èˆ¬å­—å…¸",
  "icon": "ğŸ“–",
  "category": "task_mastery",
  "requirement_type": "consecutive_days", 
  "requirement_value": 30,
  "experience_reward": 300
}"#;

        let user_message = format!("è«‹æ ¹æ“šä»¥ä¸‹ç”¨æˆ¶è¡Œç‚ºæ•¸æ“šç”Ÿæˆåˆé©çš„æˆå°±ï¼š{}", user_input);

        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt.to_string(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_message,
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_achievement_from_text] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_achievement_from_text] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            let achievement_json = &choice.message.content;
            let generated_achievement: AIGeneratedAchievement = serde_json::from_str(achievement_json)?;

            validate_generated_achievement(&generated_achievement)?;

            Ok(generated_achievement)
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_preview(&self, prompt: &str) -> Result<String> {
        let request = serde_json::json!({
            "model": self.model.clone(),
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹å……æ»¿æ´»åŠ›å’Œé¼“å‹µçš„ä»»å‹™åŠ©æ‰‹ã€‚ç”¨ç©æ¥µæ­£é¢çš„èªæ°£ç‚ºç”¨æˆ¶ä»‹ç´¹ä»»å‹™ï¼Œè®“ä»–å€‘æ„Ÿåˆ°èˆˆå¥®å’Œæœ‰å‹•åŠ›å»å®Œæˆã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_completion_tokens": 4000
        });

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_preview] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;
        
        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_preview] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;
        
        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_preview_with_history(&self, system_prompt: &str, history: &[(String, String)], current_message: &str) -> Result<String> {
        let mut messages = vec![];

        for (user_msg, assistant_msg) in history {
            messages.push(serde_json::json!({
                "role": "user",
                "content": user_msg
            }));
            messages.push(serde_json::json!({
                "role": "assistant",
                "content": assistant_msg
            }));
        }

        messages.push(serde_json::json!({
            "role": "system",
            "content": system_prompt
        }));

        messages.push(serde_json::json!({
            "role": "user",
            "content": current_message
        }));

        let request = serde_json::json!({
            "model": self.model.clone(),
            "messages": messages,
            "max_completion_tokens": 4000
        });
        
        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_preview_with_history] {}", format_ai_output(&body));
        }
        
        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;
        
        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_preview_with_history] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_from_text(&self, user_input: &str) -> Result<AIGeneratedTask> {
        let now = Utc::now();
        let current_time_str = now.to_rfc3339();

        let system_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹ä»»å‹™è¦åŠƒåŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„è‡ªç„¶èªè¨€æè¿°ï¼Œç”Ÿæˆçµæ§‹åŒ–çš„ä»»å‹™è³‡æ–™ã€‚

**é‡è¦ï¼šç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚** åœ¨ç”Ÿæˆä»»ä½•èˆ‡æ—¥æœŸç›¸é—œçš„æ¬„ä½ï¼ˆå¦‚ start_date, due_dateï¼‰æ™‚ï¼Œè«‹ä»¥æ­¤æ™‚é–“ç‚ºåŸºæº–é€²è¡Œæ¨ç®—ã€‚

**æˆªæ­¢æ—¥æœŸç”Ÿæˆè¦å‰‡ï¼š**
- å°æ–¼å¤§éƒ¨åˆ†ä»»å‹™ï¼Œä½ éƒ½æ‡‰è©²è¨­å®šä¸€å€‹åˆç†çš„æˆªæ­¢æ—¥æœŸ
- çŸ­æœŸä»»å‹™ï¼ˆ1-3å¤©å…§å®Œæˆï¼‰ï¼šè¨­å®š1-3å¤©å¾Œçš„æˆªæ­¢æ—¥æœŸ
- ä¸­æœŸä»»å‹™ï¼ˆ1-2é€±å®Œæˆï¼‰ï¼šè¨­å®š1-2é€±å¾Œçš„æˆªæ­¢æ—¥æœŸ
- é•·æœŸä»»å‹™ï¼ˆ1å€‹æœˆä»¥ä¸Šï¼‰ï¼šè¨­å®š1-3å€‹æœˆå¾Œçš„æˆªæ­¢æ—¥æœŸ
- åªæœ‰å°æ–¼æ²’æœ‰æ˜ç¢ºæ™‚é–“é™åˆ¶çš„ç¿’æ…£é¡ä»»å‹™æ‰è¨­å®š due_date ç‚º null
- å¦‚æœç”¨æˆ¶æ˜ç¢ºæåˆ°æ™‚é–“ï¼ˆå¦‚"æ˜å¤©"ã€"ä¸‹é€±"ã€"æœˆåº•"ï¼‰ï¼Œä¸€å®šè¦æ ¹æ“šç•¶å‰æ™‚é–“è¨ˆç®—å°æ‡‰çš„æˆªæ­¢æ—¥æœŸ

ä»»å‹™é¡å‹èªªæ˜ï¼š
- main: ä¸»è¦ä»»å‹™ï¼ˆé‡è¦çš„é•·æœŸç›®æ¨™ï¼Œé€šå¸¸è¨­å®šè¼ƒé•·çš„æˆªæ­¢æ—¥æœŸï¼‰
- side: å‰¯ç·šä»»å‹™ï¼ˆæ¬¡è¦çš„çŸ­æœŸä»»å‹™ï¼Œé€šå¸¸è¨­å®šè¼ƒçŸ­çš„æˆªæ­¢æ—¥æœŸï¼‰
- challenge: æŒ‘æˆ°ä»»å‹™ï¼ˆå›°é›£ä¸”æœ‰æˆå°±æ„Ÿçš„ä»»å‹™ï¼Œæ ¹æ“šå…·é«”å…§å®¹è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰
- daily: æ—¥å¸¸ä»»å‹™ï¼ˆä¾‹è¡Œæ€§ä»»å‹™ï¼Œé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰

å„ªå…ˆç´šï¼š0=ä½, 1=ä¸­, 2=é«˜
é›£åº¦ï¼š1-5ï¼ˆ1=éå¸¸ç°¡å–®, 5=éå¸¸å›°é›£ï¼‰
ç¶“é©—å€¼ï¼šæ ¹æ“šé›£åº¦å’Œé‡è¦æ€§è¨ˆç®—ï¼Œé€šå¸¸æ˜¯ difficulty * 20 + priority * 10

é‡è¤‡æ¨¡å¼ï¼ˆåƒ…é™æ—¥å¸¸ä»»å‹™ï¼‰ï¼š
- daily: æ¯å¤©
- weekdays: å·¥ä½œæ—¥
- weekends: é€±æœ«
- weekly: æ¯é€±

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
  "title": "ä»»å‹™æ¨™é¡Œ",
  "description": "ä»»å‹™æè¿°ï¼ˆé¸å¡«ï¼‰",
  "task_type": "main/side/challenge/daily",
  "priority": 0-2,
  "difficulty": 1-5,
  "experience": ç¶“é©—å€¼,
  "due_date": "æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼Œå¤§å¤šæ•¸æƒ…æ³ä¸‹éƒ½æ‡‰è©²è¨­å®šï¼‰",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}

å¦‚æœæ˜¯é‡è¤‡æ€§ä»»å‹™ï¼Œè«‹è¨­ç½®ï¼š
- is_recurring: true
- recurrence_pattern: "daily/weekdays/weekends/weekly"
- start_date: é–‹å§‹æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰
- completion_target: 0.8ï¼ˆé è¨­80%å®Œæˆç‡ç›®æ¨™ï¼‰
- due_date: nullï¼ˆé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šå–®ä¸€æˆªæ­¢æ—¥æœŸï¼‰

ç¯„ä¾‹è¼¸å…¥ï¼š"å­¸ç¿’Pythonç¨‹å¼è¨­è¨ˆ"
ç¯„ä¾‹è¼¸å‡ºï¼š
{{
  "title": "å­¸ç¿’Pythonç¨‹å¼è¨­è¨ˆ",
  "description": "ç³»çµ±æ€§å­¸ç¿’Pythonç¨‹å¼èªè¨€åŸºç¤çŸ¥è­˜",
  "task_type": "main",
  "priority": 2,
  "difficulty": 3,
  "experience": 80,
  "due_date": "2024-02-15T23:59:59Z",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}

ç¯„ä¾‹è¼¸å…¥ï¼š"æ˜å¤©äº¤å ±å‘Š"
ç¯„ä¾‹è¼¸å‡ºï¼š
{{
  "title": "å®Œæˆä¸¦æäº¤å ±å‘Š",
  "description": "æ•´ç†è³‡æ–™ä¸¦å®Œæˆå ±å‘Šæ’°å¯«",
  "task_type": "side",
  "priority": 2,
  "difficulty": 2,
  "experience": 60,
  "due_date": "2024-01-02T18:00:00Z",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}"#,
            current_time_str
        );

        let user_message = format!("è«‹æ ¹æ“šä»¥ä¸‹æè¿°ç”Ÿæˆä»»å‹™ï¼š{}", user_input);

        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_message,
                },
            ],
            max_completion_tokens: 1000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };
        log::info!("OpenRouter Request: {}", serde_json::to_string_pretty(&request).unwrap());
        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_from_text] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤: {}", error_text));
        }

        let openrouter_response: OpenRouterResponse = response.json().await?;
        
        if let Some(choice) = openrouter_response.choices.first() {
            let task_json = &choice.message.content;
            log::info!("[AI OUTPUT][generate_task_from_text] {}", format_ai_output(&task_json));
            let generated_task: AIGeneratedTask = serde_json::from_str(task_json)?;
            
            validate_generated_task(&generated_task)?;
            
            Ok(generated_task)
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    // æ–°æ–¹æ³•ï¼šåŸºäºç”¨æˆ· ID ç”Ÿæˆæˆå°±ï¼ˆä½¿ç”¨ç»Ÿè®¡æ‘˜è¦ï¼‰
    async fn generate_achievement_from_user_id(&self, rb: &RBatis, user_id: &str) -> Result<AIGeneratedAchievement> {
        // 1. ç”Ÿæˆç”¨æˆ·è¡Œä¸ºæ‘˜è¦
        log::info!("ä¸ºç”¨æˆ· {} ç”Ÿæˆè¡Œä¸ºæ‘˜è¦...", user_id);
        let summary = BehaviorAnalytics::generate_summary(rb, user_id).await?;
        log::info!("è¡Œä¸ºæ‘˜è¦ç”Ÿæˆå®Œæˆï¼šå®Œæˆ{}ä¸ªä»»åŠ¡ï¼Œæœ€é•¿è¿ç»­{}å¤©", summary.total_tasks_completed, summary.longest_streak.days);

        // 2. æ„å»ºåŸºäºæ‘˜è¦çš„ prompt
        let system_prompt = build_achievement_prompt_from_summary(&summary);

        // 3. è°ƒç”¨ AI ç”Ÿæˆæˆå°±
        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: "è«‹åŸºæ–¼ä»¥ä¸Šç”¨æˆ¶æ•¸æ“šï¼Œç”Ÿæˆä¸€å€‹æœ€åˆé©çš„æˆå°±ã€‚".to_string(),
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_achievement_from_user_id] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        log::info!("OpenRouter API éŸ¿æ‡‰ç‹€æ…‹: {}", status);

        if !status.is_success() {
            let error_text = response.text().await?;
            log::error!("OpenRouter API éŒ¯èª¤éŸ¿æ‡‰: {}", error_text);
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, error_text));
        }

        let response_text = response.text().await?;
        log::info!("OpenRouter API éŸ¿æ‡‰é•·åº¦: {} bytes", response_text.len());

        if response_text.is_empty() {
            log::error!("OpenRouter API è¿”å›ç©ºéŸ¿æ‡‰");
            return Err(anyhow::anyhow!("OpenRouter API è¿”å›ç©ºéŸ¿æ‡‰"));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)
            .map_err(|e| {
                log::error!("è§£æ OpenRouter éŸ¿æ‡‰å¤±æ•—: {}. éŸ¿æ‡‰å…§å®¹: {}", e, &response_text[..std::cmp::min(200, response_text.len())]);
                anyhow::anyhow!("è§£æ OpenRouter éŸ¿æ‡‰å¤±æ•—: {}", e)
            })?;

        if let Some(choice) = openrouter_response.choices.first() {
            let achievement_json = &choice.message.content;
            log::info!("AI è¿”å›çš„æˆå°± JSON é•·åº¦: {} å­—ç¬¦", achievement_json.len());

            let generated_achievement: AIGeneratedAchievement = serde_json::from_str(achievement_json)
                .map_err(|e| {
                    log::error!("è§£ææˆå°± JSON å¤±æ•—: {}. JSON å…§å®¹: {}", e, achievement_json);
                    anyhow::anyhow!("è§£ææˆå°± JSON å¤±æ•—: {}", e)
                })?;

            validate_generated_achievement(&generated_achievement)?;

            Ok(generated_achievement)
        } else {
            log::error!("OpenRouter éŸ¿æ‡‰ä¸­æ²’æœ‰ choices");
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn match_expert_for_task(&self, user_input: &str) -> Result<ExpertMatch> {
        let experts = get_expert_database();
        
        // æ§‹å»ºå°ˆå®¶åŒ¹é…çš„æç¤ºè©
        let expert_list = experts.iter()
            .enumerate()
            .map(|(i, expert)| {
                format!("{}. {} ({}) - å°ˆç²¾é ˜åŸŸ: {}", 
                    i + 1, 
                    expert.name, 
                    expert.emoji,
                    expert.expertise_areas.join("ã€")
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

        let system_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹å°ˆå®¶åŒ¹é…åŠ©æ‰‹ã€‚æ ¹æ“šç”¨æˆ¶çš„ä»»å‹™æè¿°ï¼Œå¾ä»¥ä¸‹å°ˆå®¶åˆ—è¡¨ä¸­é¸æ“‡æœ€é©åˆçš„å°ˆå®¶ã€‚

å¯ç”¨å°ˆå®¶åˆ—è¡¨ï¼š
{}

è«‹åˆ†æç”¨æˆ¶çš„ä»»å‹™æè¿°ï¼Œé¸æ“‡æœ€é©åˆçš„å°ˆå®¶ï¼Œä¸¦æä¾›åŒ¹é…ç†ç”±ã€‚

å›æ‡‰æ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "expert_name": "å°ˆå®¶çš„å®Œæ•´åç¨±",
  "expert_description": "å°ˆå®¶çš„è©³ç´°æè¿°",
  "confidence": åŒ¹é…ä¿¡å¿ƒåº¦ï¼ˆ0.0-1.0ï¼‰
}}

é¸æ“‡åŸå‰‡ï¼š
1. æ ¹æ“šä»»å‹™çš„æ ¸å¿ƒé ˜åŸŸé¸æ“‡å°ˆå®¶
2. è€ƒæ…®å°ˆå®¶çš„å°ˆæ¥­é ˜åŸŸæ˜¯å¦èˆ‡ä»»å‹™åŒ¹é…
3. å¦‚æœæ²’æœ‰å®Œå…¨åŒ¹é…çš„å°ˆå®¶ï¼Œé¸æ“‡æœ€æ¥è¿‘çš„
. ä¿¡å¿ƒåº¦åŸºæ–¼åŒ¹é…ç¨‹åº¦ï¼šå®Œå…¨åŒ¹é…=1.0ï¼Œéƒ¨åˆ†åŒ¹é…=0.6-0.8ï¼Œå‹‰å¼·åŒ¹é…=0.3-0.5"#,
            expert_list
        );

        log::info!("[AI INPUT][match_expert_for_task] {}", user_input);

        let request = OpenRouterRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: (&user_input).to_string(),
                },
            ],
            max_completion_tokens: 500,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][match_expert_for_task_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][match_expert_for_task] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;
        
        if let Some(choice) = openrouter_response.choices.first() {
            let match_json = &choice.message.content;
            let match_result: serde_json::Value = serde_json::from_str(match_json)?;
            
            let expert_name = match_result["expert_name"].as_str()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„å°ˆå®¶åç¨±"))?.to_string();
            
            let expert_description = match_result["expert_description"].as_str()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„å°ˆå®¶æè¿°"))?.to_string();
            
            let confidence = match_result["confidence"].as_f64()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„ä¿¡å¿ƒåº¦"))?;

            // ç›´æ¥ä½¿ç”¨AIè¿”å›çš„å°ˆå®¶ä¿¡æ¯ï¼Œå‰µå»ºè™›æ“¬å°ˆå®¶å°è±¡
            let virtual_expert = Expert {
                name: expert_name.clone(),
                description: expert_description.clone(),
                expertise_areas: vec!["AIåŒ¹é…".to_string()],
                emoji: "ğŸ¤–".to_string(),
            };

            Ok(ExpertMatch {
                expert: virtual_expert,
                confidence,
                ai_expert_name: expert_name,
                ai_expert_description: expert_description,
            })
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_with_expert(&self, user_input: &str, expert_match: &ExpertMatch) -> Result<AIGeneratedTaskPlan> {
        let now = Utc::now();
        let current_time_str = now.to_rfc3339();

        let system_prompt = format!(
            r#"ä½ æ˜¯{}ï¼Œ{}

**é‡è¦ï¼šç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚** åœ¨ç”Ÿæˆä»»ä½•èˆ‡æ—¥æœŸç›¸é—œçš„æ¬„ä½ï¼ˆå¦‚ start_date, due_dateï¼‰æ™‚ï¼Œè«‹ä»¥æ­¤æ™‚é–“ç‚ºåŸºæº–é€²è¡Œæ¨ç®—ã€‚

**æˆªæ­¢æ—¥æœŸç”Ÿæˆè¦å‰‡ï¼š**
- å°æ–¼å¤§éƒ¨åˆ†ä»»å‹™ï¼Œä½ éƒ½æ‡‰è©²è¨­å®šä¸€å€‹åˆç†çš„æˆªæ­¢æ—¥æœŸ
- çŸ­æœŸä»»å‹™ï¼ˆ1-3å¤©å…§å®Œæˆï¼‰ï¼šè¨­å®š1-3å¤©å¾Œçš„æˆªæ­¢æ—¥æœŸ
- ä¸­æœŸä»»å‹™ï¼ˆ1-2é€±å®Œæˆï¼‰ï¼šè¨­å®š1-2é€±å¾Œçš„æˆªæ­¢æ—¥æœŸ
- é•·æœŸä»»å‹™ï¼ˆ1å€‹æœˆä»¥ä¸Šï¼‰ï¼šè¨­å®š1-3å€‹æœˆå¾Œçš„æˆªæ­¢æ—¥æœŸ
- åªæœ‰å°æ–¼æ²’æœ‰æ˜ç¢ºæ™‚é–“é™åˆ¶çš„ç¿’æ…£é¡ä»»å‹™æ‰è¨­å®š due_date ç‚º null
- å¦‚æœç”¨æˆ¶æ˜ç¢ºæåˆ°æ™‚é–“ï¼ˆå¦‚"æ˜å¤©"ã€"ä¸‹é€±"ã€"æœˆåº•"ï¼‰ï¼Œä¸€å®šè¦æ ¹æ“šç•¶å‰æ™‚é–“è¨ˆç®—å°æ‡‰çš„æˆªæ­¢æ—¥æœŸ

ä»»å‹™é¡å‹èªªæ˜ï¼š
- main: ä¸»è¦ä»»å‹™ï¼ˆé‡è¦çš„é•·æœŸç›®æ¨™ï¼Œé€šå¸¸è¨­å®šè¼ƒé•·çš„æˆªæ­¢æ—¥æœŸï¼‰
- side: å‰¯ç·šä»»å‹™ï¼ˆæ¬¡è¦çš„çŸ­æœŸä»»å‹™ï¼Œé€šå¸¸è¨­å®šè¼ƒçŸ­çš„æˆªæ­¢æ—¥æœŸï¼‰
- challenge: æŒ‘æˆ°ä»»å‹™ï¼ˆå›°é›£ä¸”æœ‰æˆå°±æ„Ÿçš„ä»»å‹™ï¼Œæ ¹æ“šå…·é«”å…§å®¹è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰
- daily: æ—¥å¸¸ä»»å‹™ï¼ˆä¾‹è¡Œæ€§ä»»å‹™ï¼Œé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰

å„ªå…ˆç´šï¼š0=ä½, 1=ä¸­, 2=é«˜
é›£åº¦ï¼š1-5ï¼ˆ1=éå¸¸ç°¡å–®, 5=éå¸¸å›°é›£ï¼‰
ç¶“é©—å€¼ï¼šæ ¹æ“šé›£åº¦å’Œé‡è¦æ€§è¨ˆç®—ï¼Œé€šå¸¸æ˜¯ difficulty * 20 + priority * 10

**é‡è¦ï¼šä½ å¿…é ˆç”Ÿæˆä¸€å€‹åŒ…å«ä¸»ä»»å‹™å’Œå­ä»»å‹™çš„å®Œæ•´å­¸ç¿’è¨ˆåŠƒã€‚**

è«‹ç‚ºç”¨æˆ¶ç”Ÿæˆä¸€å€‹å®Œæ•´çš„å­¸ç¿’è¨ˆåŠƒï¼ŒåŒ…å«ï¼š
1. ä¸€å€‹ä¸»ä»»å‹™ï¼ˆæ•´é«”å­¸ç¿’ç›®æ¨™ï¼‰
2. 3-5å€‹å…·é«”çš„å­ä»»å‹™

**ä¸»ä»»å‹™è¦æ±‚ï¼š**
- ä½œç‚ºæ•´é«”å­¸ç¿’ç›®æ¨™çš„æ¦‚æ‹¬
- åŒ…å«å­¸ç¿’ç¸½çµå’Œé ä¼°å®Œæˆæ™‚é–“
- è¨­å®šç‚ºé«˜å„ªå…ˆç´šï¼ˆpriority: 2ï¼‰
- é›£åº¦è¨­ç‚ºä¸­ç­‰ï¼ˆdifficulty: 3ï¼‰
- ç¶“é©—å€¼è¨­ç‚º100

**å­ä»»å‹™è¦æ±‚ï¼š**
- ç”Ÿæˆ3-5å€‹å…·é«”çš„å­ä»»å‹™
- æ¯å€‹å­ä»»å‹™éƒ½æ‡‰è©²æœ‰æ˜ç¢ºçš„å­¸ç¿’ç›®æ¨™å’ŒåŸ·è¡Œæ­¥é©Ÿ
- å­ä»»å‹™é›£åº¦å¾ç°¡å–®åˆ°å›°é›£éå¢ï¼ˆ1-4ï¼‰
- æ¯å€‹å­ä»»å‹™éƒ½æ‡‰è©²è¨­å®šåˆç†çš„æˆªæ­¢æ—¥æœŸ
- å­ä»»å‹™é¡å‹å¯ä»¥æ˜¯ï¼šmainï¼ˆä¸»è¦å­¸ç¿’ï¼‰ã€sideï¼ˆè¼”åŠ©ç·´ç¿’ï¼‰ã€challengeï¼ˆæŒ‘æˆ°é …ç›®ï¼‰

**ä½ å¿…é ˆåš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼å›æ‡‰ï¼Œä¸èƒ½æœ‰ä»»ä½•åå·®ï¼š**

{{
  "main_task": {{
    "title": "ä¸»ä»»å‹™æ¨™é¡Œ",
    "description": "ä¸»ä»»å‹™æè¿°ï¼ŒåŒ…å«å­¸ç¿’ç¸½çµå’Œé ä¼°å®Œæˆæ™‚é–“",
    "task_type": "main",
    "priority": 2,
    "difficulty": 3,
    "experience": 100,
    "due_date": "ä¸»ä»»å‹™æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰",
    "is_recurring": false,
    "recurrence_pattern": null,
    "start_date": null,
    "end_date": null,
    "completion_target": null
  }},
  "subtasks": [
    {{
      "title": "å­ä»»å‹™1æ¨™é¡Œ",
      "description": "å­ä»»å‹™1è©³ç´°æè¿°ï¼ŒåŒ…å«å­¸ç¿’ç›®æ¨™å’ŒåŸ·è¡Œæ­¥é©Ÿ",
      "task_type": "main",
      "priority": 1,
      "difficulty": 1,
      "experience": 25,
      "due_date": "å­ä»»å‹™1æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰",
      "is_recurring": false,
      "recurrence_pattern": null,
      "start_date": null,
      "end_date": null,
      "completion_target": null
    }},
    {{
      "title": "å­ä»»å‹™2æ¨™é¡Œ",
      "description": "å­ä»»å‹™2è©³ç´°æè¿°ï¼ŒåŒ…å«å­¸ç¿’ç›®æ¨™å’ŒåŸ·è¡Œæ­¥é©Ÿ",
      "task_type": "side",
      "priority": 1,
      "difficulty": 2,
      "experience": 35,
      "due_date": "å­ä»»å‹™2æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼‰",
      "is_recurring": false,
      "recurrence_pattern": null,
      "start_date": null,
      "end_date": null,
      "completion_target": null
    }}
  ]
}}

**æ³¨æ„ï¼šä½ çš„å›æ‡‰å¿…é ˆæ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼ŒåŒ…å« main_task å’Œ subtasks å…©å€‹å­—æ®µã€‚ä¸è¦æ·»åŠ ä»»ä½•é¡å¤–çš„æ–‡å­—æˆ–è§£é‡‹ã€‚**"#,
            expert_match.ai_expert_name,
            expert_match.ai_expert_description,
            current_time_str
        );

        log::info!("[AI INPUT][generate_task_with_expert][OpenRouter] {}", user_input);

        let request = OpenRouterRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: format!("è«‹ç‚ºä»¥ä¸‹ä»»å‹™æè¿°ç”Ÿæˆè©³ç´°çš„ä»»å‹™è¦åŠƒï¼š{}", user_input),
                },
            ],
            max_completion_tokens: 2000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_with_expert_payload][OpenRouter] {}", body);
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_with_expert][OpenRouter] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            let task_json = &choice.message.content;
            let generated_task_plan: AIGeneratedTaskPlan = serde_json::from_str(task_json)?;

            validate_generated_task(&generated_task_plan.main_task)?;
            for subtask in &generated_task_plan.subtasks {
                validate_generated_task(subtask)?;
            }

            Ok(generated_task_plan)
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn analyze_with_expert(&self, user_input: &str, expert_name: &str, expert_description: &str, analysis_type: &str) -> Result<String> {
        let analysis_prompts = match analysis_type {
            "analyze" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚åˆ†æå‡º3-6å€‹é©åˆçš„åŠ å¼·æ–¹å‘ã€‚

ç”¨æˆ¶éœ€æ±‚ï¼š{}

è«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "directions": [
    {{"title": "æ–¹å‘æ¨™é¡Œ", "description": "ç°¡çŸ­æè¿°"}},
    {{"title": "æ–¹å‘æ¨™é¡Œ", "description": "ç°¡çŸ­æè¿°"}}
  ]
}}

æ¯å€‹æ–¹å‘æ¨™é¡Œè¦ç°¡æ½”æ˜ç¢ºï¼Œæè¿°è¦ç°¡çŸ­ï¼ˆä¸è¶…é20å­—ï¼‰ã€‚"#,
                expert_name, expert_description, user_input
            ),
            "goals" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚ç”Ÿæˆ3-5å€‹æ˜ç¢ºã€å¯è¡¡é‡çš„å­¸ç¿’ç›®æ¨™ã€‚ç›®æ¨™æ‡‰è©²å…·é«”ã€å¯é”æˆã€æœ‰æ™‚é–“æ€§ã€‚

ç”¨æˆ¶éœ€æ±‚ï¼š{}

è«‹ä»¥æ¸…æ™°çš„æ ¼å¼å›æ‡‰ï¼Œæ¯å€‹ç›®æ¨™ç”¨ç·¨è™Ÿåˆ—å‡ºï¼Œä¸¦èªªæ˜å¦‚ä½•è¡¡é‡é”æˆæƒ…æ³ã€‚"#,
                expert_name, expert_description, user_input
            ),
            "resources" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šç”¨æˆ¶çš„éœ€æ±‚æ¨è–¦3-5å€‹å„ªè³ªçš„å­¸ç¿’è³‡æºï¼ŒåŒ…æ‹¬æ›¸ç±ã€èª²ç¨‹ã€ç¶²ç«™ã€å·¥å…·ç­‰ã€‚

ç”¨æˆ¶éœ€æ±‚ï¼š{}

è«‹ä»¥æ¸…æ™°çš„æ ¼å¼å›æ‡‰ï¼Œæ¯å€‹è³‡æºç”¨ç·¨è™Ÿåˆ—å‡ºï¼Œä¸¦ç°¡è¦èªªæ˜ç‚ºä»€éº¼æ¨è–¦é€™å€‹è³‡æºã€‚"#,
                expert_name, expert_description, user_input
            ),
            _ => return Err(anyhow::anyhow!("ä¸æ”¯æ´çš„åˆ†æé¡å‹: {}", analysis_type)),
        };

        log::info!("[AI INPUT][analyze_with_expert] description={} type={} expert_name={} expert_description={}", user_input, analysis_type, expert_name, expert_description);

        let request = OpenAIRequest {
            model: self.model.clone().to_string(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: analysis_prompts,
                },
            ],
            max_completion_tokens: 1000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][analyze_with_expert_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][analyze_with_expert] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    // æ–°å¢ï¼šä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”Ÿæˆæ–‡å­—å›æ‡‰
    async fn generate_with_model(&self, model: &str, prompt: &str) -> Result<String> {
        // æ ¹æ“šæ¨¡å‹é¡å‹å‹•æ…‹èª¿æ•´ max_tokens
        let max_tokens = if model.contains("perplexity") {
            16000  // Perplexity æ¨¡å‹çµ¦äºˆæ›´å¤§çš„ç©ºé–“
        } else if model.contains("claude") || model.contains("anthropic") {
            8000   // Claude æ¨¡å‹éœ€è¦æ›´å¤šç©ºé–“ä¾†ç”Ÿæˆå®Œæ•´çš„ä»»å‹™ç´°ç¯€
        } else {
            4000   // å…¶ä»–æ¨¡å‹ä½¿ç”¨é è¨­å€¼
        };

        log::info!("ä½¿ç”¨æ¨¡å‹ {} ç”Ÿæˆå›æ‡‰ï¼Œmax_completion_tokens: {}", model, max_tokens);

        let request = serde_json::json!({
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_completion_tokens": max_tokens
        });

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤: {}", error_text));
        }

        let openrouter_response: OpenRouterResponse = response.json().await?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }
}

// AI æœå‹™å·¥å» å‡½æ•¸
pub fn create_ai_service(config: &AIConfig) -> Result<Box<dyn AIService + Send + Sync>> {
    match config.api_option.as_str() {
        "OpenAI" => {
            let api_key = config.openai_api_key.as_ref()
                .ok_or_else(|| anyhow::anyhow!("OpenAI API key æœªè¨­å®š"))?;
            Ok(Box::new(OpenAIService::new(api_key.clone(), config.openai_model.clone())))
        }
        "OpenRouter" => {
            let api_key = config.openrouter_api_key.as_ref()
                .ok_or_else(|| anyhow::anyhow!("OpenRouter API key æœªè¨­å®š"))?;
            Ok(Box::new(OpenRouterService::new(api_key.clone(), config.openrouter_model.clone())))
        }
        _ => Err(anyhow::anyhow!("ä¸æ”¯æ´çš„ AI æœå‹™é¸é …: {}", config.api_option))
    }
}

fn validate_generated_task(task: &AIGeneratedTask) -> Result<()> {
    // é©—è­‰ä»»å‹™é¡å‹
    if !["main", "side", "challenge", "daily"].contains(&task.task_type.as_str()) {
        return Err(anyhow::anyhow!("ç„¡æ•ˆçš„ä»»å‹™é¡å‹: {}", task.task_type));
    }

    // é©—è­‰å„ªå…ˆç´š
    if task.priority < 0 || task.priority > 2 {
        return Err(anyhow::anyhow!("å„ªå…ˆç´šå¿…é ˆåœ¨ 0-2 ä¹‹é–“"));
    }

    // é©—è­‰é›£åº¦
    if task.difficulty < 1 || task.difficulty > 5 {
        return Err(anyhow::anyhow!("é›£åº¦å¿…é ˆåœ¨ 1-5 ä¹‹é–“"));
    }

    // é©—è­‰ç¶“é©—å€¼
    if task.experience < 0 {
        return Err(anyhow::anyhow!("ç¶“é©—å€¼ä¸èƒ½ç‚ºè² æ•¸"));
    }

    // é©—è­‰é‡è¤‡æ€§ä»»å‹™è¨­ç½®
    if task.is_recurring {
        if task.recurrence_pattern.is_none() {
            return Err(anyhow::anyhow!("é‡è¤‡æ€§ä»»å‹™å¿…é ˆæŒ‡å®šé‡è¤‡æ¨¡å¼"));
        }
        
        let pattern = task.recurrence_pattern.as_ref().unwrap();
        if !["daily", "weekdays", "weekends", "weekly"].contains(&pattern.as_str()) {
            return Err(anyhow::anyhow!("ç„¡æ•ˆçš„é‡è¤‡æ¨¡å¼: {}", pattern));
        }

        if task.start_date.is_none() {
            return Err(anyhow::anyhow!("é‡è¤‡æ€§ä»»å‹™å¿…é ˆæŒ‡å®šé–‹å§‹æ—¥æœŸ"));
        }
    }

    // é©—è­‰å®Œæˆç‡ç›®æ¨™
    if let Some(target) = task.completion_target {
        if target < 0.0 || target > 1.0 {
            return Err(anyhow::anyhow!("å®Œæˆç‡ç›®æ¨™å¿…é ˆåœ¨ 0.0-1.0 ä¹‹é–“"));
        }
    }

    Ok(())
}

fn validate_generated_achievement(achievement: &AIGeneratedAchievement) -> Result<()> {
    // é©—è­‰æˆå°±åˆ†é¡
    if !["task_mastery", "consistency", "challenge_overcome", "skill_development"].contains(&achievement.category.as_str()) {
        return Err(anyhow::anyhow!("ç„¡æ•ˆçš„æˆå°±åˆ†é¡: {}", achievement.category));
    }

    // é©—è­‰é”æˆæ¢ä»¶é¡å‹ - ä½¿ç”¨æšèˆ‰çš„æœ‰æ•ˆå­—ç¬¦ä¸²åˆ—è¡¨
    let valid_requirement_types = AchievementRequirementType::all_valid_strings();
    if !valid_requirement_types.contains(&achievement.requirement_type.as_str()) {
        return Err(anyhow::anyhow!(
            "ç„¡æ•ˆçš„é”æˆæ¢ä»¶é¡å‹: {}. æœ‰æ•ˆé¡å‹: {:?}", 
            achievement.requirement_type,
            valid_requirement_types
        ));
    }

    // é©—è­‰æ¢ä»¶æ•¸å€¼
    if achievement.requirement_value <= 0 {
        return Err(anyhow::anyhow!("é”æˆæ¢ä»¶æ•¸å€¼å¿…é ˆå¤§æ–¼0"));
    }

    // é©—è­‰ç¶“é©—å€¼çå‹µ
    if achievement.experience_reward < 50 || achievement.experience_reward > 500 {
        return Err(anyhow::anyhow!("ç¶“é©—å€¼çå‹µå¿…é ˆåœ¨ 50-500 ä¹‹é–“"));
    }

    // é©—è­‰æˆå°±åç¨±é•·åº¦
    if achievement.name.len() < 2 || achievement.name.len() > 50 {
        return Err(anyhow::anyhow!("æˆå°±åç¨±é•·åº¦å¿…é ˆåœ¨ 2-50 å­—ä¹‹é–“"));
    }

    Ok(())
}

// å°‡ AI ç”Ÿæˆçš„ä»»å‹™è½‰æ›ç‚ºè³‡æ–™åº«æ¨¡å‹
pub fn convert_to_task_model(
    ai_task: AIGeneratedTask,
    user_id: String,
) -> crate::models::Task {
    use uuid::Uuid;
    
    let now = Utc::now();
    
    crate::models::Task {
        id: Some(Uuid::new_v4().to_string()),
        user_id: Some(user_id),
        title: Some(ai_task.title),
        description: ai_task.description,
        status: Some(0), // é è¨­ç‚ºå¾…è™•ç†
        priority: Some(ai_task.priority),
        task_type: Some(ai_task.task_type),
        difficulty: Some(ai_task.difficulty),
        experience: Some(ai_task.experience),
        parent_task_id: None,
        is_parent_task: Some(0),
        task_order: Some(0),
        due_date: ai_task.due_date.and_then(|d| d.parse().ok()),
        created_at: Some(now),
        updated_at: Some(now),
        is_recurring: Some(if ai_task.is_recurring { 1 } else { 0 }),
        recurrence_pattern: ai_task.recurrence_pattern,
        start_date: ai_task.start_date.and_then(|d| d.parse().ok()),
        end_date: ai_task.end_date.and_then(|d| d.parse().ok()),
        completion_target: ai_task.completion_target,
        completion_rate: Some(0.0),
        task_date: None,
        cancel_count: Some(0),
        last_cancelled_at: None,
        skill_tags: None,
        career_mainline_id: None,
        task_category: None,
        attributes: None,
    }
}

// å°‡ AI ç”Ÿæˆçš„æˆå°±è½‰æ›ç‚ºè³‡æ–™åº«æ¨¡å‹
pub fn convert_to_achievement_model(
    ai_achievement: AIGeneratedAchievement,
) -> crate::models::Achievement {
    use uuid::Uuid;
    
    let now = Utc::now();
    
    // å°‡å­—ç¬¦ä¸²è½‰æ›ç‚ºæšèˆ‰
    let requirement_type = AchievementRequirementType::from_string(&ai_achievement.requirement_type);
    
    crate::models::Achievement {
        id: Some(Uuid::new_v4().to_string()),
        name: Some(ai_achievement.name),
        description: ai_achievement.description,
        icon: ai_achievement.icon,
        category: Some(ai_achievement.category),
        requirement_type,
        requirement_value: Some(ai_achievement.requirement_value),
        experience_reward: Some(ai_achievement.experience_reward),
        created_at: Some(now),
    }
}

pub fn build_task_generation_prompt(
    user_input: &str,
    expert_match: &ExpertMatch,
    selected_options: Option<Vec<String>>,
    selected_directions: Option<Vec<AnalysisDirection>>,
    expert_outputs: Option<std::collections::HashMap<String, String>>,
    skill_label: &str,
    duration_label: &str,
) -> String {
    let mut prompt = String::new();
    prompt.push_str(user_input);

    if !skill_label.is_empty() || !duration_label.is_empty() {
        prompt.push_str("\n\nä½¿ç”¨è€…èƒŒæ™¯ï¼š");
        if !skill_label.is_empty() {
            prompt.push_str(&format!("ç†Ÿæ‚‰ç¨‹åº¦ï¼š{} ", skill_label));
        }
        if !duration_label.is_empty() {
            prompt.push_str(&format!("å­¸ç¿’æ™‚é•·ï¼š{}", duration_label));
        }
    }

    if let Some(options) = selected_options {
        if !options.is_empty() {
            let option_labels = options.join("ã€");
            prompt.push_str(&format!("\n\nè«‹ç‰¹åˆ¥é‡å°ä»¥ä¸‹éœ€æ±‚æä¾›ä»»å‹™è¼¸å‡ºï¼š{}", option_labels));
        }
    }

    if let Some(directions) = selected_directions {
        if !directions.is_empty() {
            prompt.push_str("\n\nä½¿ç”¨è€…å·²é¸æ“‡çš„é‡é»å¼·åŒ–æ–¹å‘ï¼š\n");
            for (index, direction) in directions.iter().enumerate() {
                prompt.push_str(&format!("{}. {} - {}\n", index + 1, direction.title, direction.description));
            }
        }
    }

    if let Some(outputs) = expert_outputs {
        if !outputs.is_empty() {
            prompt.push_str("\n\nå‰ä¸€æ­¥é©Ÿçš„åˆ†æçµæœï¼š\n");
            for (key, value) in outputs {
                prompt.push_str(&format!("[{}]\n{}\n\n", key, value));
            }
        }
    }

    prompt.push_str(&format!(
        "\n\nè«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šï¼Œä¸¦ä»¥{} ({}) çš„è¦–è§’ï¼Œç”¢å‡ºç¬¦åˆè¦æ±‚çš„ä»»å‹™è¦åŠƒã€‚",
        expert_match.expert.name, expert_match.expert.description
    ));

    prompt
}