use anyhow::Result;
use serde::{Deserialize, Serialize};
use serde_json::json;
use chrono::Utc;
use rbatis::RBatis;
use crate::behavior_analytics::BehaviorAnalytics;
use super::r#trait::AIService;
use super::common::{
    AIGeneratedAchievement, AIGeneratedTask, AIGeneratedTaskPlan, AIGeneratedSkillTags, ExpertMatch, Expert,
    format_ai_output, get_expert_database, build_achievement_prompt_from_summary,
    validate_generated_achievement, validate_generated_task,
    AITaskPrimaryFields, AITaskSecondaryFields, AIPlanPrimaryFields, AIPlanSecondaryFields
};

// OpenRouter API è«‹æ±‚çµæ§‹
#[derive(Serialize)]
struct OpenRouterRequest {
    model: String,
    messages: Vec<ChatMessage>,
    max_completion_tokens: i32,
    response_format: ResponseFormat,
}

// OpenRouter API å›æ‡‰çµæ§‹
#[derive(Deserialize)]
struct OpenRouterResponse {
    choices: Vec<Choice>,
}


#[derive(Serialize)]
struct ResponseFormat {
    #[serde(rename = "type")]
    format_type: String,
}

#[derive(Serialize, Deserialize)]
struct ChatMessage {
    role: String,
    content: String,
}

#[derive(Deserialize)]
struct Choice {
    message: ChatMessage,
}

pub struct OpenRouterService {
    api_key: String,
    model: String,
    model_small: String,
    model_fast: String,
    model_normal: String,
    model_think: String,
    model_background: String,
    client: reqwest::Client,
}

impl OpenRouterService {
    pub fn new(api_key: String, model: String, model_small: String, model_fast: String, model_normal: String, model_think: String, model_background: String) -> Self {
        Self {
            api_key,
            model,
            model_small,
            model_fast,
            model_normal,
            model_think,
            model_background,
            client: reqwest::Client::new(),
        }
    }

    // æ ¹æ“šæ¨¡å‹ç­‰ç´šç²å–å°æ‡‰æ¨¡å‹
    fn get_model_by_tier(&self, tier: super::common::ModelTier) -> &str {
        use super::common::ModelTier;
        match tier {
            ModelTier::Small => &self.model_small,
            ModelTier::Fast => &self.model_fast,
            ModelTier::Normal => &self.model_normal,
            ModelTier::Think => &self.model_think,
            ModelTier::Background => &self.model_background,
        }
    }
}

#[async_trait::async_trait]
impl AIService for OpenRouterService {
    async fn generate_achievement_from_text(&self, user_input: &str) -> Result<AIGeneratedAchievement> {
        let system_prompt = r#"ä½ æ˜¯ä¸€å€‹æˆå°±è¨­è¨ˆåŠ©æ‰‹ã€‚æ ¹æ“šä½¿ç”¨è€…çš„è¡Œç‚ºè³‡æ–™åˆ†æï¼Œç”Ÿæˆå€‹æ€§åŒ–ä¸”å…·æœ‰æ¿€å‹µæ€§çš„æˆå°±ã€‚

è«‹ä»”ç´°åˆ†æä½¿ç”¨è€…çš„ï¼š
1. å·²æœ‰æˆå°±åˆ—è¡¨
2. ä»»å‹™å®Œæˆç‹€æ³
3. ä»»å‹™å–æ¶ˆ/å¤±æ•—ç‹€æ³
4. å¾…å®Œæˆä»»å‹™

**è¨­è¨ˆåŸå‰‡ï¼š**
- æˆå°±åç¨±è¦å¹½é»˜ä¸”å…·é«”ï¼Œå¦‚ã€Œæˆç‚ºè‹±èªå­—å…¸ã€ã€Œè·‘ç«å…¥é­”ã€
- åŸºæ–¼ä½¿ç”¨è€…å¯¦éš›è¡Œç‚ºæ¨¡å¼ç”Ÿæˆï¼Œä¸è¦æ†‘ç©ºæƒ³åƒ
- å¦‚æœä½¿ç”¨è€…åœ¨æŸé ˜åŸŸå·²æœ‰åŸºç¤æˆå°±ä¸”è¡¨ç¾å„ªç§€ï¼Œå¯è€ƒæ…®å‡ç´šç‰ˆæˆå°±
- é¿å…èˆ‡ç¾æœ‰æˆå°±é‡è¤‡

**æˆå°±åˆ†é¡ï¼š**
- task_mastery: ä»»å‹™ç²¾é€šé¡
- consistency: æŒçºŒæ€§é¡
- challenge_overcome: å…‹æœæŒ‘æˆ°é¡
- skill_development: æŠ€èƒ½ç™¼å±•é¡

**é”æˆæ¢ä»¶é¡å‹ï¼š**
- consecutive_days: é€£çºŒå¤©æ•¸
- total_completions: ç¸½å®Œæˆæ¬¡æ•¸
- task_complete: å®Œæˆä»»å‹™ç¸½æ•¸
- streak_recovery: å¾å¤±æ•—ä¸­æ¢å¾©
- skill_level: æŠ€èƒ½ç­‰ç´š
- learning_task_complete: å­¸ç¿’ä»»å‹™å®Œæˆ
- intelligence_attribute: æ™ºåŠ›å±¬æ€§é”æˆ
- endurance_attribute: æ¯…åŠ›å±¬æ€§é”æˆ
- creativity_attribute: å‰µé€ åŠ›å±¬æ€§é”æˆ
- social_attribute: ç¤¾äº¤åŠ›å±¬æ€§é”æˆ
- focus_attribute: å°ˆæ³¨åŠ›å±¬æ€§é”æˆ
- adaptability_attribute: é©æ‡‰åŠ›å±¬æ€§é”æˆ

**ç¶“é©—å€¼çå‹µè¨ˆç®—ï¼š**
- åŸºæ–¼é›£åº¦ï¼šç°¡å–®æˆå°± 50-100ï¼Œä¸­ç­‰ 100-200ï¼Œå›°é›£ 200-500

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{
  "name": "æˆå°±åç¨±ï¼ˆå¹½é»˜ä¸”å…·é«”ï¼‰",
  "description": "æˆå°±æè¿°ï¼ˆé¸å¡«ï¼‰",
  "icon": "åœ–æ¨™åç¨±ï¼ˆé¸å¡«ï¼‰",
  "category": "æˆå°±åˆ†é¡",
  "requirement_type": "é”æˆæ¢ä»¶é¡å‹",
  "requirement_value": æ•¸å€¼,
  "experience_reward": ç¶“é©—å€¼çå‹µ
}

ç¯„ä¾‹ï¼š
è¼¸å…¥ï¼šä½¿ç”¨è€…é€£çºŒå®Œæˆã€ŒèƒŒè‹±èªå–®å­—ã€30å¤©ï¼Œä½†ç¶“å¸¸å–æ¶ˆã€Œé‹å‹•ã€ä»»å‹™
è¼¸å‡ºï¼š
{
  "name": "æˆç‚ºè‹±èªå­—å…¸",
  "description": "é€£çºŒ30å¤©å®ŒæˆèƒŒè‹±èªå–®å­—ï¼Œè©å½™é‡å·²ç¶“è¶…è¶Šä¸€èˆ¬å­—å…¸",
  "icon": "ğŸ“–",
  "category": "task_mastery",
  "requirement_type": "consecutive_days",
  "requirement_value": 30,
  "experience_reward": 300
}"#;

        let user_message = format!("è«‹æ ¹æ“šä»¥ä¸‹ä½¿ç”¨è€…è¡Œç‚ºè³‡æ–™ç”Ÿæˆåˆé©çš„æˆå°±ï¼š{}", user_input);

        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt.to_string(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_message,
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_achievement_from_text] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_achievement_from_text] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            let achievement_json = &choice.message.content;
            let generated_achievement: AIGeneratedAchievement = serde_json::from_str(achievement_json)?;

            validate_generated_achievement(&generated_achievement)?;

            Ok(generated_achievement)
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_achievement_from_user_id(&self, rb: &RBatis, user_id: &str) -> Result<AIGeneratedAchievement> {
        // 1. ç”Ÿæˆä½¿ç”¨è€…è¡Œç‚ºæ‘˜è¦
        log::info!("ç‚ºä½¿ç”¨è€… {} ç”Ÿæˆè¡Œç‚ºæ‘˜è¦...", user_id);
        let summary = BehaviorAnalytics::generate_summary(rb, user_id).await?;
        log::info!("è¡Œç‚ºæ‘˜è¦ç”Ÿæˆå®Œæˆï¼šå®Œæˆ{}å€‹ä»»å‹™ï¼Œæœ€é•·é€£çºŒ{}å¤©", summary.total_tasks_completed, summary.longest_streak.days);

        // 2. æ§‹å»ºåŸºæ–¼æ‘˜è¦çš„ prompt
        let system_prompt = build_achievement_prompt_from_summary(&summary);

        // 3. å‘¼å« AI ç”Ÿæˆæˆå°±
        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: "è«‹åŸºæ–¼ä»¥ä¸Šä½¿ç”¨è€…è³‡æ–™ï¼Œç”Ÿæˆä¸€å€‹æœ€åˆé©çš„æˆå°±ã€‚".to_string(),
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_achievement_from_user_id] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        log::info!("OpenRouter API éŸ¿æ‡‰ç‹€æ…‹: {}", status);

        if !status.is_success() {
            let error_text = response.text().await?;
            log::error!("OpenRouter API éŒ¯èª¤éŸ¿æ‡‰: {}", error_text);
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, error_text));
        }

        let response_text = response.text().await?;
        log::info!("OpenRouter API éŸ¿æ‡‰é•·åº¦: {} bytes", response_text.len());

        if response_text.is_empty() {
            log::error!("OpenRouter API è¿”å›ç©ºéŸ¿æ‡‰");
            return Err(anyhow::anyhow!("OpenRouter API è¿”å›ç©ºéŸ¿æ‡‰"));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)
            .map_err(|e| {
                let preview = response_text.chars().take(200).collect::<String>();
                log::error!("è§£æ OpenRouter éŸ¿æ‡‰å¤±æ•—: {}. éŸ¿æ‡‰å…§å®¹: {}", e, preview);
                anyhow::anyhow!("è§£æ OpenRouter éŸ¿æ‡‰å¤±æ•—: {}", e)
            })?;

        if let Some(choice) = openrouter_response.choices.first() {
            let achievement_json = &choice.message.content;
            log::info!("AI è¿”å›çš„æˆå°± JSON é•·åº¦: {} å­—ç¬¦", achievement_json.len());

            let generated_achievement: AIGeneratedAchievement = serde_json::from_str(achievement_json)
                .map_err(|e| {
                    log::error!("è§£ææˆå°± JSON å¤±æ•—: {}. JSON å…§å®¹: {}", e, achievement_json);
                    anyhow::anyhow!("è§£ææˆå°± JSON å¤±æ•—: {}", e)
                })?;

            validate_generated_achievement(&generated_achievement)?;

            Ok(generated_achievement)
        } else {
            log::error!("OpenRouter éŸ¿æ‡‰ä¸­æ²’æœ‰ choices");
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_preview(&self, prompt: &str) -> Result<String> {
        let request = serde_json::json!({
            "model": self.model.clone(),
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹å……æ»¿æ´»åŠ›å’Œé¼“å‹µçš„ä»»å‹™åŠ©æ‰‹ã€‚ç”¨ç©æ¥µæ­£é¢çš„èªæ°£ç‚ºä½¿ç”¨è€…ä»‹ç´¹ä»»å‹™ï¼Œè®“ä»–å€‘æ„Ÿåˆ°èˆˆå¥®å’Œæœ‰å‹•åŠ›å»å®Œæˆã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_completion_tokens": 4000
        });

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_preview] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_preview] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_preview_with_history(&self, system_prompt: &str, history: &[(String, String)], current_message: &str) -> Result<String> {
        let mut messages = vec![];

        for (user_msg, assistant_msg) in history {
            messages.push(serde_json::json!({
                "role": "user",
                "content": user_msg
            }));
            messages.push(serde_json::json!({
                "role": "assistant",
                "content": assistant_msg
            }));
        }

        messages.push(serde_json::json!({
            "role": "system",
            "content": system_prompt
        }));

        messages.push(serde_json::json!({
            "role": "user",
            "content": current_message
        }));

        let request = serde_json::json!({
            "model": self.model.clone(),
            "messages": messages,
            "max_completion_tokens": 4000
        });

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_task_preview_with_history] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][generate_task_preview_with_history] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_from_text(&self, user_input: &str) -> Result<AIGeneratedTask> {
        let now = Utc::now();
        let current_time_str = now.format("%Y-%m-%dT%H:%M:%S").to_string();

        let primary_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹ä»»å‹™è¦åŠƒåŠ©æ‰‹ã€‚æ ¹æ“šä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€æè¿°ï¼Œå…ˆç”Ÿæˆä»»å‹™çš„ä¸»è¦æ¬„ä½ã€‚

**é‡è¦ï¼šç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚** åœ¨ç”Ÿæˆä»»ä½•èˆ‡æ—¥æœŸç›¸é—œçš„æ¬„ä½ï¼ˆå¦‚ due_dateï¼‰æ™‚ï¼Œè«‹ä»¥æ­¤æ™‚é–“ç‚ºåŸºæº–é€²è¡Œæ¨ç®—ã€‚

**æˆªæ­¢æ—¥æœŸç”Ÿæˆè¦å‰‡ï¼š**
- å°æ–¼å¤§éƒ¨åˆ†ä»»å‹™ï¼Œä½ éƒ½æ‡‰è©²è¨­å®šä¸€å€‹åˆç†çš„æˆªæ­¢æ—¥æœŸ
- çŸ­æœŸä»»å‹™ï¼ˆ1-3å¤©å…§å®Œæˆï¼‰ï¼šè¨­å®š1-3å¤©å¾Œçš„æˆªæ­¢æ—¥æœŸ
- ä¸­æœŸä»»å‹™ï¼ˆ1-2é€±å®Œæˆï¼‰ï¼šè¨­å®š1-2é€±å¾Œçš„æˆªæ­¢æ—¥æœŸ
- é•·æœŸä»»å‹™ï¼ˆ1å€‹æœˆä»¥ä¸Šï¼‰ï¼šè¨­å®š1-3å€‹æœˆå¾Œçš„æˆªæ­¢æ—¥æœŸ
- åªæœ‰å°æ–¼æ²’æœ‰æ˜ç¢ºæ™‚é–“é™åˆ¶çš„ç¿’æ…£é¡ä»»å‹™æ‰è¨­å®š due_date ç‚º null
- å¦‚æœä½¿ç”¨è€…æ˜ç¢ºæåˆ°æ™‚é–“ï¼ˆå¦‚"æ˜å¤©"ã€"ä¸‹é€±"ã€"æœˆåº•"ï¼‰ï¼Œä¸€å®šè¦æ ¹æ“šç•¶å‰æ™‚é–“è¨ˆç®—å°æ‡‰çš„æˆªæ­¢æ—¥æœŸ

ä»»å‹™é¡å‹èªªæ˜ï¼š
- main: ä¸»è¦ä»»å‹™ï¼ˆé‡è¦çš„é•·æœŸç›®æ¨™ï¼Œé€šå¸¸è¨­å®šè¼ƒé•·çš„æˆªæ­¢æ—¥æœŸï¼‰
- side: å‰¯ç·šä»»å‹™ï¼ˆæ¬¡è¦çš„çŸ­æœŸä»»å‹™ï¼Œé€šå¸¸è¨­å®šè¼ƒçŸ­çš„æˆªæ­¢æ—¥æœŸï¼‰
- challenge: æŒ‘æˆ°ä»»å‹™ï¼ˆå›°é›£ä¸”æœ‰æˆå°±æ„Ÿçš„ä»»å‹™ï¼Œæ ¹æ“šå…·é«”å…§å®¹è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰
- daily: æ—¥å¸¸ä»»å‹™ï¼ˆä¾‹è¡Œæ€§ä»»å‹™ï¼Œé‡è¤‡æ€§ä»»å‹™é€šå¸¸ä¸è¨­å®šæˆªæ­¢æ—¥æœŸï¼‰

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
  "title": "ä»»å‹™æ¨™é¡Œ",
  "description": "ä»»å‹™æè¿°ï¼ˆé¸å¡«ï¼‰",
  "task_type": "main/side/challenge/daily",
  "due_date": "æˆªæ­¢æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼Œå¤§å¤šæ•¸æƒ…æ³ä¸‹éƒ½æ‡‰è©²è¨­å®šï¼Œè‹¥ç‚ºé‡è¤‡æ€§ä»»å‹™å‰‡ç‚º nullï¼‰",
  "recurrence_pattern": "é‡è¤‡æ¨¡å¼ï¼ˆåƒ…åœ¨é‡è¤‡æ€§ä»»å‹™æ™‚å¡«å¯«ï¼Œå¦å‰‡ç‚º nullï¼‰"
}}

è‹¥åˆ¤å®šç‚ºé‡è¤‡æ€§ä»»å‹™ï¼Œrecurrence_pattern å¿…é ˆæ˜¯ "daily"ã€"weekdays"ã€"weekends" æˆ– "weekly"ï¼Œä¸” due_date å¿…é ˆç‚º nullã€‚
"#,
            current_time_str
        );

        let primary_request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: primary_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: format!("è«‹æ ¹æ“šä»¥ä¸‹æè¿°ç”Ÿæˆä»»å‹™ä¸»è¦æ¬„ä½ï¼š{}", user_input),
                },
            ],
            max_completion_tokens: 2000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&primary_request) {
            log::info!("[AI INPUT][generate_task_from_text_primary] {}", format_ai_output(&body));
        }

        let primary_response = self
            .client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&primary_request)
            .send()
            .await?;

        let primary_status = primary_response.status();
        let primary_text = primary_response.text().await?;
        log::info!("[AI OUTPUT][generate_task_from_text_primary] {}", format_ai_output(&primary_text));

        if !primary_status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ (primary) ({}): {}", primary_status, primary_text));
        }

        let primary_parsed: OpenRouterResponse = serde_json::from_str(&primary_text)?;
        let primary_choice = primary_parsed
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆä¸»æ¬„ä½"))?;

        let primary_task: AITaskPrimaryFields = serde_json::from_str(&primary_choice.message.content)?;

        let secondary_prompt = format!(
            r#"åŸºæ–¼ä»¥ä¸‹ä»»å‹™ä¸»è¦æ¬„ä½è³‡è¨Šï¼Œè£œå…¨å‰©é¤˜æ¬„ä½ã€‚

**ä»»å‹™ä¸»è¦æ¬„ä½ï¼š**
{}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
  "priority": 0-2,
  "difficulty": 1-5,
  "experience": ç¶“é©—å€¼,
  "is_recurring": å¸ƒæ—å€¼,
  "completion_target": å®Œæˆç‡ç›®æ¨™ï¼ˆé‡è¤‡æ€§ä»»å‹™æ™‚æä¾›ï¼Œå¦å‰‡ç‚º nullï¼‰ï¼Œ
  "start_date": "é–‹å§‹æ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼Œåƒ…åœ¨éœ€è¦æ™‚æä¾›ï¼‰",
  "end_date": "çµæŸæ—¥æœŸï¼ˆISO 8601æ ¼å¼ï¼Œåƒ…åœ¨éœ€è¦æ™‚æä¾›ï¼‰"
}}

è¦å‰‡ï¼š
- å„ªå…ˆç´šï¼š0=ä½, 1=ä¸­, 2=é«˜ã€‚
- é›£åº¦ï¼š1=éå¸¸ç°¡å–®, 5=éå¸¸å›°é›£ã€‚
- ç¶“é©—å€¼é€šå¸¸æ˜¯ difficulty * 20 + priority * 10ã€‚
- è‹¥ä»»å‹™ç‚ºé‡è¤‡æ€§ï¼Œis_recurring æ‡‰ç‚º trueï¼Œcompletion_target é è¨­ 0.8ï¼Œstart_date éœ€æä¾›ï¼Œdue_date ä¿æŒç‚º nullã€‚
- è‹¥éé‡è¤‡æ€§ä»»å‹™ï¼Œis_recurring ç‚º falseï¼Œcompletion_targetã€start_dateã€end_date é è¨­ç‚º nullã€‚
"#,
            serde_json::to_string_pretty(&primary_task)?
        );

        let secondary_request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: secondary_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: "è«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Šè£œå…¨å‰©é¤˜æ¬„ä½".to_string(),
                },
            ],
            max_completion_tokens: 2000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&secondary_request) {
            log::info!("[AI INPUT][generate_task_from_text_secondary] {}", format_ai_output(&body));
        }

        let secondary_response = self
            .client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&secondary_request)
            .send()
            .await?;

        let secondary_status = secondary_response.status();
        let secondary_text = secondary_response.text().await?;
        log::info!("[AI OUTPUT][generate_task_from_text_secondary] {}", format_ai_output(&secondary_text));

        if !secondary_status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ (secondary) ({}): {}", secondary_status, secondary_text));
        }

        let secondary_parsed: OpenRouterResponse = serde_json::from_str(&secondary_text)?;
        let secondary_choice = secondary_parsed
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆæ¬¡æ¬„ä½"))?;

        let secondary_task: AITaskSecondaryFields = serde_json::from_str(&secondary_choice.message.content)?;

        let combined_task = AIGeneratedTask {
            title: primary_task.title,
            description: primary_task.description,
            task_type: primary_task.task_type,
            priority: secondary_task.priority,
            difficulty: secondary_task.difficulty,
            experience: secondary_task.experience,
            due_date: primary_task.due_date,
            is_recurring: secondary_task.is_recurring,
            recurrence_pattern: primary_task.recurrence_pattern,
            start_date: secondary_task.start_date,
            end_date: secondary_task.end_date,
            completion_target: secondary_task.completion_target,
        }
        .with_defaults()
        .normalize_recurring();

        let validated_task = validate_generated_task(&combined_task)?;

        Ok(validated_task)
    }

    async fn generate_daily_task_from_text(&self, user_input: &str) -> Result<AIGeneratedTask> {
        let primary_prompt = r#"ä½ æ˜¯ä¸€å€‹æ¯æ—¥ä»»å‹™è¦åŠƒåŠ©æ‰‹ã€‚æ ¹æ“šä½¿ç”¨è€…çš„æè¿°ï¼Œç”Ÿæˆé©åˆæ¯å¤©åŸ·è¡Œçš„æ—¥å¸¸ä»»å‹™ã€‚

**æ¯æ—¥ä»»å‹™ç‰¹æ€§ï¼š**
- é€™æ˜¯éœ€è¦æ¯å¤©é‡è¤‡åŸ·è¡Œçš„ç¿’æ…£æˆ–ä¾‹è¡Œäº‹é …
- ä»»å‹™æ‡‰è©²ç°¡å–®æ˜ç¢ºï¼Œå®¹æ˜“åœ¨ä¸€å¤©å…§å®Œæˆ
- é€šå¸¸æ˜¯å¥åº·ã€å­¸ç¿’ã€å·¥ä½œã€ç”Ÿæ´»ç¿’æ…£ç›¸é—œ
- ä¸è¨­å®šæˆªæ­¢æ—¥æœŸï¼ˆdue_date ç‚º nullï¼‰
- task_type å›ºå®šç‚º "daily"

**ä½¿ç”¨è€…æŠ€èƒ½æ°´æº–é©æ‡‰ï¼ˆé‡è¦ï¼‰ï¼š**
- **å‹™å¿…ä»”ç´°åˆ†æä½¿ç”¨è€…çš„æŠ€èƒ½æ°´æº–**ï¼Œå¾æè¿°ä¸­æ¨æ–·å…¶ç†Ÿæ‚‰ç¨‹åº¦ï¼ˆå¦‚ã€Œæƒ³å­¸ã€ã€ã€Œåˆå­¸ã€ã€ã€Œå·²ç¶“åœ¨åšã€ç­‰é—œéµå­—ï¼‰
- **åˆå­¸è€…/å…¥é–€éšæ®µ**ï¼šå¾æœ€åŸºç¤ã€ä½é–€æª»çš„ä»»å‹™é–‹å§‹
  * ä¾‹å¦‚æƒ³å­¸ç™»å±± â†’ ã€Œèµ°æ¨“æ¢¯10åˆ†é˜ã€ã€ã€Œåœ¨å¹³åœ°å¥èµ°20åˆ†é˜ã€è€Œéç›´æ¥ç™»å±±
  * ä¾‹å¦‚æƒ³å­¸è‹±èª â†’ ã€Œå­¸ç¿’5å€‹åŸºç¤å–®å­—ã€ã€ã€Œè½è‹±æ–‡æ­Œæ›²10åˆ†é˜ã€è€Œéé–±è®€æ–‡ç« 
  * é›£åº¦è¨­ç‚º 1ï¼Œé¿å…éåº¦æŒ‘æˆ°å°è‡´æ”¾æ£„
- **ä¸­ç´šéšæ®µ**ï¼šæœ‰ä¸€å®šåŸºç¤ï¼Œå¯é©åº¦å¢åŠ é›£åº¦
  * ä¾‹å¦‚ç™»å±±ä¸­ç´šè€… â†’ ã€Œçˆ¬éƒŠå±±æ­¥é“30åˆ†é˜ã€ã€ã€Œè² é‡å¥èµ°ã€
  * ä¾‹å¦‚è‹±èªä¸­ç´šè€… â†’ ã€Œé–±è®€ç°¡å–®è‹±æ–‡æ–‡ç« ã€ã€ã€Œç·´ç¿’æ—¥å¸¸å°è©±ã€
  * é›£åº¦è¨­ç‚º 2
- **è³‡æ·±/å°ˆå®¶éšæ®µ**ï¼šå·²æœ‰è±å¯Œç¶“é©—ï¼Œå¯è¨­å®šå°ˆæ¥­æŒ‘æˆ°
  * ä¾‹å¦‚ç™»å±±è³‡æ·±è€… â†’ ã€Œç™»å°å±±ã€ã€ã€Œé€²éšç™»å±±è¨“ç·´ã€
  * ä¾‹å¦‚è‹±èªå°ˆå®¶ â†’ ã€Œæ’°å¯«è‹±æ–‡æ–‡ç« ã€ã€ã€Œè‹±æ–‡æ¼”è¬›ç·´ç¿’ã€
  * é›£åº¦è¨­ç‚º 3
- **æ¼¸é€²å¼è¨­è¨ˆåŸå‰‡**ï¼šç¢ºä¿ä»»å‹™ç¬¦åˆä½¿ç”¨è€…ç•¶å‰èƒ½åŠ›ï¼Œé¿å…ä¸€é–‹å§‹å°±è¦æ±‚éé«˜è€Œå°è‡´æŒ«æŠ˜

**ä»»å‹™é›£åº¦å’Œç¶“é©—å€¼è¨­å®šï¼š**
- ç°¡å–®çš„æ—¥å¸¸ç¿’æ…£ï¼ˆå¦‚å–æ°´8æ¯ã€è¨˜éŒ„å¿ƒæƒ…ã€èµ°æ¨“æ¢¯ï¼‰ï¼šdifficulty=1, experience=5
- éœ€è¦ä¸€å®šåŸ·è¡Œæ™‚é–“çš„ä»»å‹™ï¼ˆå¦‚é‹å‹•30åˆ†é˜ã€é–±è®€20é ï¼‰ï¼šdifficulty=2, experience=10
- éœ€è¦å°ˆæ³¨åŠ›å’ŒæŒçºŒæ€§çš„ä»»å‹™ï¼ˆå¦‚å­¸ç¿’æ–°æŠ€èƒ½1å°æ™‚ã€å†¥æƒ³30åˆ†é˜ã€å°ˆæ¥­è¨“ç·´ï¼‰ï¼šdifficulty=3, experience=15

**ä»»å‹™é¡å‹èªªæ˜ï¼š**
- æ¯æ—¥ä»»å‹™çš„ task_type å¿…é ˆæ˜¯ "daily"
- é€™é¡ä»»å‹™é©åˆé¤Šæˆç¿’æ…£ï¼Œæ¯å¤©éƒ½å¯ä»¥é‡è¤‡åŸ·è¡Œ
- ä¸è¦è¨­å®šæˆªæ­¢æ—¥æœŸï¼Œå› ç‚ºé€™æ˜¯æŒçºŒæ€§çš„ç¿’æ…£

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{
  "title": "ä»»å‹™æ¨™é¡Œï¼ˆç°¡æ½”æ˜ç¢ºï¼Œä¾‹å¦‚ï¼šæ¯æ—¥èµ°æ¨“æ¢¯10åˆ†é˜ï¼‰",
  "description": "ä»»å‹™æè¿°ï¼ˆå¯é¸ï¼Œèªªæ˜å¦‚ä½•åŸ·è¡Œé€™å€‹ç¿’æ…£ï¼Œä¸¦é¼“å‹µä½¿ç”¨è€…å¾ªåºæ¼¸é€²ï¼‰",
  "task_type": "daily",
  "priority": 0-2,
  "difficulty": 1-3,
  "experience": 5-15,
  "due_date": null,
  "is_recurring": false,
  "recurrence_pattern": null
}
"#;

        let request = OpenRouterRequest {
            model: self.model_fast.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: primary_prompt.to_string(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: format!("è«‹æ ¹æ“šä»¥ä¸‹æè¿°ç”Ÿæˆæ¯æ—¥ä»»å‹™ï¼š{}", user_input),
                },
            ],
            max_completion_tokens: 1000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][generate_daily_task_from_text] {}", format_ai_output(&body));
        }

        let response = self
            .client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let text = response.text().await?;
        log::info!("[AI OUTPUT][generate_daily_task_from_text] {}", format_ai_output(&text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, text));
        }

        let parsed: OpenRouterResponse = serde_json::from_str(&text)?;
        let choice = parsed
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))?;

        let daily_task: AIGeneratedTask = serde_json::from_str(&choice.message.content)?;

        // å¼·åˆ¶è¨­å®šæ¯æ—¥ä»»å‹™çš„ç‰¹å®šå±¬æ€§
        let daily_task_normalized = AIGeneratedTask {
            title: daily_task.title,
            description: daily_task.description,
            task_type: Some("daily".to_string()), // å¼·åˆ¶ç‚º daily
            priority: daily_task.priority,
            difficulty: daily_task.difficulty.or(Some(2)), // é è¨­é›£åº¦ç‚º 2
            experience: daily_task.experience.or(Some(10)), // é è¨­ç¶“é©—å€¼ç‚º 10
            due_date: None, // å¼·åˆ¶ç‚º null
            is_recurring: Some(false),
            recurrence_pattern: None,
            start_date: None,
            end_date: None,
            completion_target: None,
        };

        let validated_task = validate_generated_task(&daily_task_normalized)?;

        Ok(validated_task)
    }

    async fn match_expert_for_task(&self, user_input: &str) -> Result<ExpertMatch> {
        let experts = get_expert_database();

        // æ§‹å»ºå°ˆå®¶åŒ¹é…çš„æç¤ºè©
        let expert_list = experts.iter()
            .enumerate()
            .map(|(i, expert)| {
                format!("{}. {} ({}) - å°ˆç²¾é ˜åŸŸ: {}",
                    i + 1,
                    expert.name,
                    expert.emoji,
                    expert.expertise_areas.join("ã€")
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

        let system_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹å°ˆå®¶åŒ¹é…åŠ©æ‰‹ã€‚æ ¹æ“šä½¿ç”¨è€…çš„ä»»å‹™æè¿°ï¼Œå¾ä»¥ä¸‹å°ˆå®¶åˆ—è¡¨ä¸­é¸æ“‡æœ€é©åˆçš„å°ˆå®¶ã€‚

å¯ç”¨å°ˆå®¶åˆ—è¡¨ï¼š
{}

è«‹åˆ†æä½¿ç”¨è€…çš„ä»»å‹™æè¿°ï¼Œé¸æ“‡æœ€é©åˆçš„å°ˆå®¶ï¼Œä¸¦æä¾›åŒ¹é…ç†ç”±ã€‚
é¸æ“‡åŸå‰‡ï¼š
1. æ ¹æ“šä»»å‹™çš„æ ¸å¿ƒé ˜åŸŸé¸æ“‡å°ˆå®¶ï¼Œåªèƒ½é¸ä¸€å€‹
2. è€ƒæ…®å°ˆå®¶çš„å°ˆæ¥­é ˜åŸŸæ˜¯å¦èˆ‡ä»»å‹™åŒ¹é…
å›æ‡‰æ ¼å¼ï¼ˆJSONï¼‰ï¼Œå¿…éœ€åš´æ ¼éµå®ˆï¼š
{{
  "expert_name": "å°ˆå®¶çš„å®Œæ•´åç¨±",
  "expert_description": "å°ˆå®¶çš„è©³ç´°æè¿°"
}}
"#,
            expert_list
        );

        log::info!("[AI INPUT][match_expert_for_task] {}", user_input);

        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: user_input.to_string(),
                },
            ],
            max_completion_tokens: 500,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][match_expert_for_task_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][match_expert_for_task] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            let match_json = &choice.message.content;
            let match_result: serde_json::Value = serde_json::from_str(match_json)?;

            let expert_name = match_result["expert_name"].as_str()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„å°ˆå®¶åç¨±"))?.to_string();

            let expert_description = match_result["expert_description"].as_str()
                .ok_or_else(|| anyhow::anyhow!("ç„¡æ•ˆçš„å°ˆå®¶æè¿°"))?.to_string();

            // ç›´æ¥ä½¿ç”¨AIè¿”å›çš„å°ˆå®¶ä¿¡æ¯ï¼Œå‰µå»ºè™›æ“¬å°ˆå®¶å°è±¡
            let virtual_expert = Expert {
                name: expert_name.clone(),
                description: expert_description.clone(),
                expertise_areas: vec!["AIåŒ¹é…".to_string()],
                emoji: "ğŸ¤–".to_string(),
            };

            Ok(ExpertMatch {
                expert: virtual_expert,
                ai_expert_name: expert_name,
                ai_expert_description: expert_description,
            })
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_task_with_expert(&self, user_input: &str, expert_match: &ExpertMatch) -> Result<AIGeneratedTaskPlan> {
        let now = Utc::now();
        let current_time_str = now.format("%Y-%m-%dT%H:%M:%S").to_string();

        let system_prompt = format!(
            r#"ä½ æ˜¯{}ï¼Œ{}

**é‡è¦ï¼šç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚** åœ¨ç”Ÿæˆä»»ä½•èˆ‡æ—¥æœŸç›¸é—œçš„æ¬„ä½ï¼ˆå¦‚ due_dateï¼‰æ™‚ï¼Œè«‹ä»¥æ­¤æ™‚é–“ç‚ºåŸºæº–é€²è¡Œæ¨ç®—ã€‚

è«‹æ ¹æ“šä½¿ç”¨è€…éœ€æ±‚ç”Ÿæˆä¸€å€‹å®Œæ•´çš„å­¸ç¿’ä»»å‹™ã€‚

è¦æ±‚ï¼š
1. ä¸»ä»»å‹™ä½œç‚ºæ•´é«”å­¸ç¿’ç›®æ¨™ï¼Œtask_type å¿…é ˆç‚º "main"
2. ä»»å‹™æè¿°æ‡‰è©²ç°¡å–®æ˜ç¢º
3. å­¸ç¿’å‹ä»»å‹™ä¸è¨­ç‚ºé‡è¤‡æ€§ï¼Œis_recurring å¿…é ˆç‚º falseï¼Œrecurrence_pattern å¿…é ˆç‚º null
4. ä¸»ä»»å‹™å›ºå®šè¨­ç½®ï¼špriority = 2ã€difficulty = 3ã€experience = 100
5. ä¸éœ€è¦è¨­ç½® start_dateã€end_dateã€completion_targetï¼ˆå…¨éƒ¨ç‚º nullï¼‰

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ‰€æœ‰æ¬„ä½ï¼š
{{
  "title": "ä»»å‹™æ¨™é¡Œ(ç¹é«”ä¸­æ–‡)",
  "description": "è©³ç´°æè¿°ï¼ˆåŒ…å«å­¸ç¿’ç›®æ¨™å’Œæ–¹æ³•å»ºè­°ï¼Œç¹é«”ä¸­æ–‡ï¼‰",
  "task_type": "main",
  "priority": 2,
  "difficulty": 3,
  "experience": 100,
  "due_date": "ISO 8601 æ ¼å¼æ™‚é–“æˆ– null",
  "is_recurring": false,
  "recurrence_pattern": null,
  "start_date": null,
  "end_date": null,
  "completion_target": null
}}

ä¸è¦è¼¸å‡ºå…¶ä»–æ¬„ä½æˆ–é¡å¤–æ–‡å­—ã€‚"#,
            expert_match.ai_expert_name,
            expert_match.ai_expert_description,
            current_time_str
        );

        let request = OpenRouterRequest {
            model: self.model_fast.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt,
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: format!("è«‹æ ¹æ“šä»¥ä¸‹æè¿°ç”Ÿæˆå®Œæ•´çš„å­¸ç¿’ä»»å‹™ï¼š{}", user_input),
                },
            ],
            max_completion_tokens: 3000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!(
                "[AI INPUT][generate_task_with_expert][OpenRouter] {}",
                format_ai_output(&body)
            );
        }

        let response = self
            .client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!(
            "[AI OUTPUT][generate_task_with_expert][OpenRouter] {}",
            format_ai_output(&response_text)
        );

        if !status.is_success() {
            return Err(anyhow::anyhow!(
                "OpenRouter API éŒ¯èª¤ ({}): {}",
                status,
                response_text
            ));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;
        let choice = openrouter_response
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))?;

        // ç›´æ¥è§£æç‚º AIGeneratedTask
        let mut main_task: AIGeneratedTask = serde_json::from_str(&choice.message.content)?;

        // ç¢ºä¿è¨­ç½®æ­£ç¢ºçš„é»˜èªå€¼
        main_task.task_type = Some("main".to_string());
        main_task.priority = Some(2);
        main_task.difficulty = Some(3);
        main_task.experience = Some(100);
        main_task.is_recurring = Some(false);
        main_task.recurrence_pattern = None;
        main_task.start_date = None;
        main_task.end_date = None;
        main_task.completion_target = None;

        let main_task = main_task.with_defaults().normalize_recurring();
        let validated_main_task = validate_generated_task(&main_task)?;

        // ä¸ç”Ÿæˆå­ä»»å‹™
        let subtasks: Vec<AIGeneratedTask> = Vec::new();

        Ok(AIGeneratedTaskPlan {
            main_task: validated_main_task,
            subtasks,
        })
    }

    async fn analyze_with_expert(&self, user_input: &str, expert_name: &str, expert_description: &str, analysis_type: &str) -> Result<String> {
        let analysis_prompts = match analysis_type {
            "analyze" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šä½¿ç”¨è€…çš„éœ€æ±‚åˆ†æå‡º3-6å€‹é©åˆçš„åŠ å¼·æ–¹å‘ã€‚

ä½¿ç”¨è€…éœ€æ±‚ï¼š{}

è«‹ä»¥JSONæ ¼å¼åŠ ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "directions": [
    {{"title": "æ–¹å‘æ¨™é¡Œ", "description": "ç°¡çŸ­æè¿°"}},
    {{"title": "æ–¹å‘æ¨™é¡Œ", "description": "ç°¡çŸ­æè¿°"}}
    ...
  ]
}}

æ¯å€‹æ–¹å‘æ¨™é¡Œè¦ç°¡æ½”æ˜ç¢ºï¼Œæè¿°è¦ç°¡çŸ­ï¼ˆä¸è¶…é20å­—ï¼‰ã€‚"#,
                expert_name, expert_description, user_input
            ),
            "goals" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šä½¿ç”¨è€…çš„éœ€æ±‚ç”Ÿæˆ4-6å€‹æ˜ç¢ºã€å¯è¡¡é‡çš„å­¸ç¿’ç›®æ¨™ã€‚ç›®æ¨™æ‡‰è©²å…·é«”ã€å¯é”æˆã€æœ‰æ™‚é–“æ€§ã€‚

ä½¿ç”¨è€…éœ€æ±‚ï¼š{}

è«‹ä»¥JSONæ ¼å¼åŠ ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "goals": [
    {{"title": "ç›®æ¨™æ¨™é¡Œ", "description": "å…·é«”æè¿°å’Œè¡¡é‡æ¨™æº–"}},
    {{"title": "ç›®æ¨™æ¨™é¡Œ", "description": "å…·é«”æè¿°å’Œè¡¡é‡æ¨™æº–"}},
    ...
  ]
}}

å¿…é ˆè¿”å›æ°å¥½5å€‹ç›®æ¨™ã€‚æ¯å€‹ç›®æ¨™æ¨™é¡Œè¦ç°¡æ½”æ˜ç¢ºï¼Œæè¿°è¦åŒ…å«å…·é«”çš„è¡¡é‡æ¨™æº–ï¼ˆä¸è¶…é30å­—ï¼‰ã€‚"#,
                expert_name, expert_description, user_input
            ),
            "resources" => format!(
                r#"ä½ æ˜¯{}ï¼Œ{}

è«‹æ ¹æ“šä½¿ç”¨è€…çš„éœ€æ±‚æ¨è–¦4-6å€‹å„ªè³ªçš„å­¸ç¿’è³‡æºï¼ŒåŒ…æ‹¬æ›¸ç±ã€èª²ç¨‹ã€ç¶²ç«™ã€å·¥å…·ç­‰ã€‚

ä½¿ç”¨è€…éœ€æ±‚ï¼š{}

è«‹ä»¥JSONæ ¼å¼åŠ ç¹é«”ä¸­æ–‡å›æ‡‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "resources": [
    {{"title": "è³‡æºåç¨±", "description": "è³‡æºæè¿°å’Œæ¨è–¦ç†ç”±"}},
    {{"title": "è³‡æºåç¨±", "description": "è³‡æºæè¿°å’Œæ¨è–¦ç†ç”±"}},
    ...
  ]
}}

å¿…é ˆè¿”å›æ°å¥½5å€‹å­¸ç¿’è³‡æºã€‚æ¯å€‹è³‡æºåç¨±è¦ç°¡æ½”æ˜ç¢ºï¼Œæè¿°è¦ç°¡çŸ­èªªæ˜ç‚ºä»€éº¼æ¨è–¦ï¼ˆä¸è¶…é30å­—ï¼‰ã€‚"#,
                expert_name, expert_description, user_input
            ),
            _ => return Err(anyhow::anyhow!("ä¸æ”¯æ´çš„åˆ†æé¡å‹: {}", analysis_type)),
        };

        log::info!("[AI INPUT][analyze_with_expert] description={} type={} expert_name={} expert_description={}", user_input, analysis_type, expert_name, expert_description);

        let request = OpenRouterRequest {
            model: self.model_fast.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: analysis_prompts,
                },
            ],
            max_completion_tokens: 4000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][analyze_with_expert_payload] {}", format_ai_output(&body));
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let response_text = response.text().await?;
        log::info!("[AI OUTPUT][analyze_with_expert] {}", format_ai_output(&response_text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, response_text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&response_text)?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn generate_subtasks_for_main_task(&self, main_task_title: &str, main_task_description: &str, expert_match: &ExpertMatch) -> Result<Vec<AIGeneratedTask>> {
        let now = Utc::now();
        let current_time_str = now.format("%Y-%m-%dT%H:%M:%S").to_string();

        let prompt = format!(
            r#"ä½ æ˜¯{}ï¼Œ{}

ç¾åœ¨çš„æ™‚é–“æ˜¯ {}ã€‚

å·²æœ‰ä¸»ä»»å‹™ï¼š
æ¨™é¡Œï¼š{}
æè¿°ï¼š{}

è«‹ç‚ºé€™å€‹ä¸»ä»»å‹™ç”Ÿæˆ 5 å€‹å…·é«”å¯åŸ·è¡Œçš„å­ä»»å‹™ã€‚
è·Ÿä¸€å€‹æ¯æ—¥ä»»å‹™ï¼Œæ¯æ—¥ä»»å‹™çš„ task_type å¿…é ˆç‚º "daily"
è¦æ±‚ï¼š
- æ¯å€‹å­ä»»å‹™æ‡‰è©²æ˜ç¢ºå…·é«”ï¼Œå¯ç›´æ¥åŸ·è¡Œ
- å­ä»»å‹™çš„ task_type å¯ç‚º "main","side","challenge","daily"
- é›£åº¦éå¢ï¼ˆ1-4ï¼‰ï¼Œå¾ç°¡å–®åˆ°å›°é›£
- æä¾›åˆç†çš„ç¶“é©—å€¼ï¼ˆ10-50ï¼‰
- å­ä»»å‹™ä¸éœ€è¦è¨­å®šæˆªæ­¢æ™‚é–“

å›æ‡‰æ ¼å¼ï¼š
{{
  "subtasks": [
    {{
      "title": "...",
      "description": "...",
      "task_type": "main/side/challenge",
      "priority": 1-3,
      "difficulty": 1-4,
      "experience": 10-50,
      "due_date": null,
      "is_recurring": false,
      "recurrence_pattern": null
    }}
  ]
}}

è«‹åªç”Ÿæˆå­ä»»å‹™ï¼Œä¸è¦é‡è¤‡ä¸»ä»»å‹™ã€‚"#,
            expert_match.ai_expert_name,
            expert_match.ai_expert_description,
            current_time_str,
            main_task_title,
            main_task_description
        );

        let request = OpenRouterRequest {
            model: self.model.clone(),
            messages: vec![
                ChatMessage {
                    role: "user".to_string(),
                    content: prompt,
                },
            ],
            max_completion_tokens: 2000,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("X-Title", "LifeUp")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let text = response.text().await?;

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤: {}", text));
        }

        let openrouter_response: OpenRouterResponse = serde_json::from_str(&text)?;
        let choice = openrouter_response
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå­ä»»å‹™"))?;

        // è§£æè¿”å›çš„JSON
        let subtasks_response: serde_json::Value = serde_json::from_str(&choice.message.content)?;
        let subtasks_array = subtasks_response["subtasks"]
            .as_array()
            .ok_or_else(|| anyhow::anyhow!("æœªæ‰¾åˆ°å­ä»»å‹™é™£åˆ—"))?;

        let mut result = Vec::new();
        for subtask_json in subtasks_array {
            let subtask = AIGeneratedTask {
                title: subtask_json["title"].as_str().map(String::from),
                description: subtask_json["description"].as_str().map(String::from),
                task_type: subtask_json["task_type"].as_str().map(String::from),
                priority: subtask_json["priority"].as_i64().map(|v| v as i32),
                difficulty: subtask_json["difficulty"].as_i64().map(|v| v as i32),
                experience: subtask_json["experience"].as_i64().map(|v| v as i32),
                due_date: None,
                is_recurring: Some(false),
                recurrence_pattern: None,
                start_date: None,
                end_date: None,
                completion_target: None,
            };
            result.push(subtask.with_defaults());
        }

        log::info!("æˆåŠŸç”Ÿæˆ {} å€‹å­ä»»å‹™", result.len());
        Ok(result)
    }

    async fn generate_with_model(&self, model: &str, prompt: &str) -> Result<String> {
        // æ ¹æ“šæ¨¡å‹é¡å‹å‹•æ…‹èª¿æ•´ max_tokens
        let max_tokens = if model.contains("perplexity") {
            16000  // Perplexity æ¨¡å‹çµ¦äºˆæ›´å¤§çš„ç©ºé–“
        } else if model.contains("gpt-oss-120b") {
            12000  // GPT-OSS-120B å¤§æ¨¡å‹éœ€è¦æ›´å¤šç©ºé–“ä¾†ç”Ÿæˆå®Œæ•´çš„ä»»å‹™ç´°ç¯€
        } else if model.contains("claude") || model.contains("anthropic") {
            8000   // Claude æ¨¡å‹éœ€è¦æ›´å¤šç©ºé–“ä¾†ç”Ÿæˆå®Œæ•´çš„ä»»å‹™ç´°ç¯€
        } else if model.contains("gpt-4o") && !model.contains("mini") {
            8000   // GPT-4o (é mini) æ”¯æŒæ›´é•·çš„è¼¸å‡º
        } else if model.contains("deepseek") || model.contains("o1") || model.contains("gpt-5") {
            6000   // DeepSeek/o1/gpt-5 ç­‰æ–°æ¨¡å‹çµ¦äºˆè¼ƒå¤šç©ºé–“
        } else if model.contains("gpt") {
            6000   // å…¶ä»– GPT æ¨¡å‹ï¼ˆåŒ…æ‹¬ gpt-4o-miniï¼‰çµ¦äºˆè¼ƒå¤šç©ºé–“
        } else {
            4000   // å…¶ä»–æ¨¡å‹ä½¿ç”¨é è¨­å€¼
        };

        log::info!("ä½¿ç”¨æ¨¡å‹ {} ç”Ÿæˆå›æ‡‰ï¼Œmax_completion_tokens: {}", model, max_tokens);

        // å»ºæ§‹åŸºæœ¬è«‹æ±‚
        let mut request = serde_json::json!({
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_completion_tokens": max_tokens
        });

        // è‹¥æ˜¯ Perplexity æ¨¡å‹ï¼Œæ·»åŠ  web_search_options å•Ÿç”¨æœå°‹åŠŸèƒ½
        if model.contains("perplexity") {
            request["web_search_options"] = serde_json::json!({
                "search_context_size": "medium"  // ä½¿ç”¨ medium å¹³è¡¡æˆæœ¬èˆ‡æœå°‹å“è³ª
            });
            log::info!("ğŸ” ç‚º Perplexity æ¨¡å‹å•Ÿç”¨ç¶²è·¯æœå°‹åŠŸèƒ½ (search_context_size: medium)");
        }

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤: {}", error_text));
        }

        let openrouter_response: OpenRouterResponse = response.json().await?;

        if let Some(choice) = openrouter_response.choices.first() {
            Ok(choice.message.content.clone())
        } else {
            Err(anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))
        }
    }

    async fn classify_user_intent(&self, user_input: &str) -> Result<crate::ai_tasks::ClassifyIntentResponse> {
        let system_prompt = r#"ä½ æ˜¯ä¸€å€‹æ™ºèƒ½ä»»å‹™æ„åœ–åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯åˆ†æä½¿ç”¨è€…çš„è¼¸å…¥,åˆ¤æ–·ä»–å€‘æ˜¯æƒ³è¦:
1. **è©³ç´°ä»»å‹™** (detailed_task): ç”¨æˆ¶å·²ç¶“æœ‰æ˜ç¢ºçš„è¨ˆåŠƒå’Œè©³ç´°æè¿°,å¯ä»¥ç›´æ¥è½‰æ›ç‚ºå…·é«”ä»»å‹™
2. **æ¨¡ç³Šç›®æ¨™** (vague_goal): ç”¨æˆ¶åªæœ‰ä¸€å€‹å¤§è‡´çš„æƒ³æ³•æˆ–ç›®æ¨™,éœ€è¦å°ˆå®¶å”åŠ©è¦åŠƒå’Œç´°åŒ–

**åˆ¤æ–·æ¨™æº–:**

è©³ç´°ä»»å‹™çš„ç‰¹å¾µ:
- åŒ…å«æ˜ç¢ºçš„è¡Œå‹•æ­¥é©Ÿæˆ–å…·é«”åšæ³•
- æœ‰æ™‚é–“å®‰æ’ã€é »ç‡æè¿°(ä¾‹å¦‚:æ¯å¤©ã€æ¯é€±ã€æŒçºŒ3å€‹æœˆ)
- æè¿°äº†å…·é«”è¦é”æˆä»€éº¼(ä¾‹å¦‚:é–±è®€æŸæœ¬æ›¸ã€å®ŒæˆæŸå€‹é …ç›®ã€ç·´ç¿’æŸå€‹æŠ€èƒ½30åˆ†é˜)
- æåˆ°äº†å…·é«”çš„è³‡æºã€å·¥å…·æˆ–æ–¹æ³•
- ä½¿ç”¨äº†ã€Œæˆ‘è¦åš...ã€ã€ã€Œè¨ˆåŠƒ...ã€ã€ã€Œæ¯å¤©...ã€ç­‰è¡Œå‹•å°å‘çš„è©å½™
- ä¾‹å¦‚: "æˆ‘æƒ³æ¯å¤©æ—©ä¸Šæ…¢è·‘30åˆ†é˜,æŒçºŒ3å€‹æœˆ"ã€"å­¸ç¿’Python,æ¯å¤©å¯«ä»£ç¢¼1å°æ™‚"ã€"é–±è®€ã€ŠåŸå­ç¿’æ…£ã€‹,æ¯å¤©20é "

æ¨¡ç³Šç›®æ¨™çš„ç‰¹å¾µ:
- åªè¡¨é”äº†ä¸€å€‹é¡˜æœ›æˆ–èˆˆè¶£,æ²’æœ‰å…·é«”è¨ˆåŠƒ
- ä½¿ç”¨ã€Œæƒ³å­¸...ã€ã€ã€Œå°...æ„Ÿèˆˆè¶£ã€ã€ã€Œå¸Œæœ›...ã€ç­‰é¡˜æœ›æ€§è©å½™
- æ²’æœ‰æåŠå…·é«”çš„åŸ·è¡Œæ–¹å¼ã€æ™‚é–“å®‰æ’
- ç¼ºä¹æ˜ç¢ºçš„è¡¡é‡æ¨™æº–æˆ–éšæ®µæ€§ç›®æ¨™
- ä¾‹å¦‚: "æˆ‘æƒ³å­¸å¯«å°èªª"ã€"æƒ³æå‡ç™»å±±èƒ½åŠ›"ã€"å°æ”å½±æ„Ÿèˆˆè¶£"ã€"æƒ³è®Šå¾—æ›´å¥åº·"

**ä»»å‹™é¡å‹å»ºè­°:**
- å¦‚æœæ˜¯è©³ç´°ä»»å‹™ä¸”æè¿°æ¯æ—¥é‡è¤‡: task_type = "daily"
- å¦‚æœæ˜¯è©³ç´°ä»»å‹™ä¸”æ˜¯é•·æœŸç›®æ¨™: task_type = "main"
- å¦‚æœæ˜¯è©³ç´°ä»»å‹™ä¸”æ˜¯ä¸­çŸ­æœŸé …ç›®: task_type = "side"
- å¦‚æœæ˜¯æ¨¡ç³Šç›®æ¨™: ä¸å»ºè­°task_type,éœ€è¦å°ˆå®¶å”åŠ©è¦åŠƒ

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰:
{
  "intent_type": "detailed_task æˆ– vague_goal",
  "confidence": 0.0åˆ°1.0çš„ä¿¡å¿ƒåº¦,
  "suggested_task_type": "main/side/daily/null",
  "reasoning": "ç°¡çŸ­èªªæ˜ä½ çš„åˆ¤æ–·ç†ç”±(30å­—ä»¥å…§)"
}
"#;

        let request = OpenRouterRequest {
            model: self.model_fast.clone(),
            messages: vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: system_prompt.to_string(),
                },
                ChatMessage {
                    role: "user".to_string(),
                    content: format!("è«‹åˆ†æä»¥ä¸‹ç”¨æˆ¶è¼¸å…¥çš„æ„åœ–:\n\n{}", user_input),
                },
            ],
            max_completion_tokens: 500,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        if let Ok(body) = serde_json::to_string(&request) {
            log::info!("[AI INPUT][classify_user_intent] {}", format_ai_output(&body));
        }

        let response = self
            .client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://openrouter.ai")
            .header("X-Title", "LifeUp Backend")
            .json(&request)
            .send()
            .await?;

        let status = response.status();
        let text = response.text().await?;
        log::info!("[AI OUTPUT][classify_user_intent] {}", format_ai_output(&text));

        if !status.is_success() {
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤ ({}): {}", status, text));
        }

        let parsed: OpenRouterResponse = serde_json::from_str(&text)?;
        let choice = parsed
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))?;

        let classification: crate::ai_tasks::ClassifyIntentResponse =
            serde_json::from_str(&choice.message.content)?;

        Ok(classification)
    }

    async fn generate_skill_tags(
        &self,
        task_title: &str,
        task_description: Option<&str>,
        user_existing_skills: &[String]
    ) -> Result<AIGeneratedSkillTags> {
        // ä½¿ç”¨ Fast æ¨¡å‹é€²è¡Œå¿«é€ŸæŠ€èƒ½æ¨™ç±¤ç”Ÿæˆ
        let model = self.get_model_by_tier(super::common::ModelTier::Fast);

        // æ§‹å»ºæç¤ºè©
        let existing_skills_str = if user_existing_skills.is_empty() {
            "ï¼ˆä½¿ç”¨è€…ç›®å‰é‚„æ²’æœ‰ä»»ä½•æŠ€èƒ½ï¼‰".to_string()
        } else {
            user_existing_skills.join("ã€")
        };

        let description_part = task_description
            .map(|d| format!("\nä»»å‹™æè¿°ï¼š{}", d))
            .unwrap_or_default();

        let system_prompt = format!(
            r#"ä½ æ˜¯ä¸€å€‹æŠ€èƒ½æ¨™ç±¤ç”ŸæˆåŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯ç‚ºä½¿ç”¨è€…çš„ä»»å‹™ç”Ÿæˆ 1-3 å€‹ç›¸é—œæŠ€èƒ½æ¨™ç±¤ï¼Œä¸¦æ¨™è¨»æ¯å€‹æŠ€èƒ½å°æ‡‰çš„å…­å¤§å±¬æ€§ã€‚

**é‡è¦ï¼šä½ å¿…é ˆåªè¿”å› JSON æ ¼å¼ï¼Œä¸è¦è¿”å›å…¶ä»–å…§å®¹ï¼**

ä½¿ç”¨è€…ç¾æœ‰æŠ€èƒ½ï¼š{}

**å…­å¤§å±¬æ€§å®šç¾©ï¼š**
- intelligence (æ™ºåŠ›): å­¸ç¿’ã€åˆ†æã€é‚è¼¯æ€è€ƒã€ç¨‹å¼è¨­è¨ˆã€ç ”ç©¶ç­‰
- endurance (æ¯…åŠ›): å …æŒã€å¥èº«ã€é•·æœŸç›®æ¨™ã€è‡ªå¾‹ã€è€åŠ›ç­‰
- creativity (å‰µé€ åŠ›): è—è¡“ã€è¨­è¨ˆã€å‰µæ„æ€è€ƒã€å¯«ä½œã€éŸ³æ¨‚ç­‰
- social (ç¤¾äº¤åŠ›): æºé€šã€åœ˜éšŠåˆä½œã€äººéš›é—œä¿‚ã€æ¼”è¬›ã€é ˜å°ç­‰
- focus (å°ˆæ³¨åŠ›): å°ˆæ³¨ã€æ•ˆç‡ã€æ™‚é–“ç®¡ç†ã€ä»»å‹™åŸ·è¡Œã€ç´°ç¯€è™•ç†ç­‰
- adaptability (é©æ‡‰åŠ›): å­¸ç¿’æ–°äº‹ç‰©ã€è§£æ±ºå•é¡Œã€æ‡‰è®Šèƒ½åŠ›ã€å¤šä»»å‹™è™•ç†ç­‰

è¦å‰‡ï¼š
1. å„ªå…ˆä½¿ç”¨ä½¿ç”¨è€…ç¾æœ‰çš„æŠ€èƒ½åç¨±
2. æŠ€èƒ½åç¨±è¦ç°¡æ½”æ˜ç¢ºï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œæœ€å¤š 6 å€‹å­—
3. è¿”å› 1-3 å€‹æŠ€èƒ½
4. æŠ€èƒ½æ‡‰è©²æ˜¯é€šç”¨é¡å‹ï¼Œä¾‹å¦‚ï¼šã€Œçƒ¹é£ªã€ã€ŒPython ç¨‹å¼è¨­è¨ˆã€ã€Œæ™‚é–“ç®¡ç†ã€
5. ç‚ºæ¯å€‹æŠ€èƒ½é¸æ“‡æœ€ç›¸é—œçš„å±¬æ€§ï¼ˆå¾å…­å¤§å±¬æ€§ä¸­é¸ä¸€å€‹ï¼‰

å¿…é ˆè¿”å›æ­¤ JSON æ ¼å¼ï¼š
{{
  "skills": [
    {{"skill": "æŠ€èƒ½åç¨±", "attribute": "intelligence"}},
    {{"skill": "æŠ€èƒ½åç¨±", "attribute": "focus"}}
  ]
}}"#,
            existing_skills_str
        );

        let user_prompt = format!(
            "ä»»å‹™åç¨±ï¼š{}{}",
            task_title,
            description_part
        );

        log::info!("ğŸ¯ ç”ŸæˆæŠ€èƒ½æ¨™ç±¤ - ä»»å‹™: {}", task_title);
        log::debug!("ç¾æœ‰æŠ€èƒ½æ•¸é‡: {}", user_existing_skills.len());

        // åˆä½µ system prompt å’Œ user prompt
        let combined_prompt = format!("{}\n\n{}", system_prompt, user_prompt);

        let request = OpenRouterRequest {
            model: model.to_string(),
            messages: vec![
                ChatMessage {
                    role: "user".to_string(),
                    content: combined_prompt,
                },
            ],
            max_completion_tokens: 500,
            response_format: ResponseFormat {
                format_type: "json_object".to_string(),
            },
        };

        let response = self
            .client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_else(|_| "ç„¡æ³•è®€å–éŒ¯èª¤è¨Šæ¯".to_string());
            log::error!("OpenRouter API éŒ¯èª¤ ({}): {}", status, error_text);
            return Err(anyhow::anyhow!("OpenRouter API éŒ¯èª¤: {} - {}", status, error_text));
        }

        let text = response.text().await?;
        log::debug!("OpenRouter åŸå§‹å›æ‡‰: {}", text);

        let parsed: OpenRouterResponse = serde_json::from_str(&text)?;
        let choice = parsed
            .choices
            .first()
            .ok_or_else(|| anyhow::anyhow!("OpenRouter æœªè¿”å›æœ‰æ•ˆå›æ‡‰"))?;

        // æ¸…ç† AI å›æ‡‰å…§å®¹ï¼Œç§»é™¤å¯èƒ½çš„ä»£ç¢¼å¡Šæ¨™è¨˜
        let content = choice.message.content.trim();
        let cleaned_content = if content.starts_with("```json") {
            // ç§»é™¤ ```json é–‹é ­å’Œ ``` çµå°¾
            content
                .strip_prefix("```json")
                .unwrap_or(content)
                .strip_suffix("```")
                .unwrap_or(content)
                .trim()
        } else if content.starts_with("```") {
            // ç§»é™¤ ``` é–‹é ­å’Œ ``` çµå°¾
            content
                .strip_prefix("```")
                .unwrap_or(content)
                .strip_suffix("```")
                .unwrap_or(content)
                .trim()
        } else {
            content
        };

        log::debug!("æ¸…ç†å¾Œçš„å…§å®¹: {}", cleaned_content);

        let skill_tags: AIGeneratedSkillTags = serde_json::from_str(cleaned_content)
            .map_err(|e| {
                log::error!("è§£ææŠ€èƒ½æ¨™ç±¤å¤±æ•—: {}", e);
                log::error!("AI å›æ‡‰å…§å®¹: {}", choice.message.content);
                log::error!("æ¸…ç†å¾Œå…§å®¹: {}", cleaned_content);
                anyhow::anyhow!("è§£æ AI å›æ‡‰å¤±æ•—: {}", e)
            })?;

        log::info!("âœ… ç”ŸæˆæŠ€èƒ½æ¨™ç±¤æˆåŠŸ: {:?}", skill_tags.skills);

        Ok(skill_tags)
    }
}